{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequences Scrapping Automatically\n",
    "This notebook is a tool I've developed to automate the process of retrieving 16S rRNA sequences of specific genera from the GenBank database, which is maintained by the National Center for Biotechnology Information (NCBI). The sequences I'm focusing on are those found in various water bodies, as identified in my study.\n",
    "\n",
    "My script reads a list of these genera, connects to the NCBI, and then iterates over the list, making a search request to the NCBI for each genus. The results are then stored in a dictionary. My ultimate goal is to align these sequences and use them to construct a dendrogram. This dendrogram will provide a visual representation of the comparative genomic relationships among the genera at the different sites and with the corresponding corrosion categories. Ultimately I am interested in understanding the genetic relationships and evolutionary history of the microbial communities found at different sites."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am having problems installilng packages from the terminal, so I am installing the biophyton from here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!{sys.executable} -m pip install requests biopython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the necesary libraries\n",
    "from Bio import Entrez\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comunicating with the NCBI\n",
    "Entrez.email = \"wattsbeatrizamanda@gmail.com\"\n",
    "Entrez.api_key = \"01d2f369faef0e78cd4906063672fab7c809\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the Excel file\n",
    "df = pd.read_excel(\"data/genera.xlsx\")\n",
    "\n",
    "# Get the list of genera\n",
    "genera = df[\"Genus\"].tolist()\n",
    "# Dictionary to store the results\n",
    "results = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If necesary it is possible to retrieve only the wild strains and water environments like this \n",
    "```search_term = f\"{genus}[Orgn] AND 16S rRNA[Gene] AND wild[Properties] AND water[Environment]\"\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I silence the following code so that I dont run it again by mistake and ask again the accession numbers to the NCBI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Loop over the genera names\\nfor genus in genera:\\n    search_term = f\"{genus}[Orgn] AND 16S rRNA[Gene]\"\\n    handle = Entrez.esearch(db=\"nucleotide\", term=search_term)\\n    record = Entrez.read(handle)\\n    results[genus] = record[\"IdList\"]\\n    time.sleep(10)  # pause for 10 seconds\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# Loop over the genera names\n",
    "for genus in genera:\n",
    "    search_term = f\"{genus}[Orgn] AND 16S rRNA[Gene]\"\n",
    "    handle = Entrez.esearch(db=\"nucleotide\", term=search_term)\n",
    "    record = Entrez.read(handle)\n",
    "    results[genus] = record[\"IdList\"]\n",
    "    time.sleep(10)  # pause for 10 seconds\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the results\n",
    "for genus, ids in results.items():\n",
    "    print(f\"{genus}: {ids}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Genus</th>\n",
       "      <th>IDs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Genus, IDs]\n",
       "Index: []"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a DataFrame from the dictionary\n",
    "df_sequences = pd.DataFrame(list(results.items()), columns=['Genus', 'IDs'])\n",
    "df_sequences.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the two DataFrames on the 'Genus' column\n",
    "merged_sequences = pd.merge(df, df_sequences, on='Genus')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Save the merged sequences to use making the dendrogram notebook\n",
    "merged_sequences.to_csv('data/sequences.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These numbers are the GenBank accession numbers, which are unique identifiers for sequences in the GenBank database. Following is to retrieve the actual sequences using these accession numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import Entrez, SeqIO\n",
    "\n",
    "# Specify your email (required by NCBI)\n",
    "Entrez.email = \"wattsbeatrizamanda@gmail.com\"\n",
    "\n",
    "# Retrieve the sequence for a given accession number\n",
    "def get_sequence(accession):\n",
    "    try:  \n",
    "        handle = Entrez.efetch(db=\"nucleotide\", id=accession, rettype=\"gb\", retmode=\"text\")\n",
    "        record = SeqIO.read(handle, \"genbank\")\n",
    "        handle.close()\n",
    "        return record.seq\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Kingdom</th>\n",
       "      <th>Phylum</th>\n",
       "      <th>Class</th>\n",
       "      <th>Order</th>\n",
       "      <th>Familia</th>\n",
       "      <th>Genus</th>\n",
       "      <th>GID</th>\n",
       "      <th>IDs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Kingdom, Phylum, Class, Order, Familia, Genus, GID, IDs]\n",
       "Index: []"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the first 10 rows of the DataFrame, just to try\n",
    "merged_sample = merged_sequences.head(10)\n",
    "merged_sample.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make the df with the accension numbers with the actual number and not just the index, code difficult to run in this machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results =[]\n",
    "\n",
    "# to use instead so that it could write down the actual accession number instead of the index per row\n",
    "# Loop over the rows in the DataFrame\n",
    "for i, row in merged_sequences.iterrows():\n",
    "    # Get the genus, GID and accession numbers for the current row\n",
    "    genus = row['Genus']\n",
    "    gid = row['GID']\n",
    "    accession_numbers = row['IDs']\n",
    "    \n",
    "    # Initialize a variable to store the accession number that returns a valid sequence\n",
    "    valid_accession = None\n",
    "    \n",
    "    # Loop over the accession numbers\n",
    "    for accession in accession_numbers:\n",
    "        # Retrieve the sequence\n",
    "        sequence = get_sequence(accession)\n",
    "        \n",
    "        # Check if a sequence was found\n",
    "        if sequence is not None:\n",
    "            # Store the accession number and break the loop\n",
    "            valid_accession = accession\n",
    "            break\n",
    "\n",
    "    # Check if a valid accession number was found\n",
    "    if valid_accession is not None:\n",
    "        # Store the result in the list\n",
    "        results.append({'Genus': genus, 'GID': gid, 'Accession': valid_accession, 'Sequence': sequence})\n",
    "\n",
    "    # Pause for 5 second\n",
    "    time.sleep(5)\n",
    "\n",
    "# Convert the list of results to a DataFrame\n",
    "final_sequences = pd.DataFrame(results)\n",
    "\n",
    "# Print the first few rows of the DataFrame\n",
    "final_sequences.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a random sample of 10 rows\n",
    "sample = final_sequences.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accession number: 219903933\n",
      "Sequence from NCBI: None\n",
      "Sequence from final_sequences: GCTTAACACATGCAAGTCGAACGGGCGTAGCAATACGTCAGTGGCAGACGGGTGAGTAACACGTGGGAACCTTCCTCGTAGTACGGAACAACTCAGGGAAACTTGAGCTAATACCGTATACGTCCGAGAGGAGAAAGATTTATCGCTATGAGACGGGCCCGCGTCCGATTAGCTAGTTGGTGGGGTAACGGCCTACCAAGGCAACGATCGGTAGCTGATCTGAGAGGATGATCAGCCACACTGGGACTGAGACACGGCCCAGACTCCTACGGGAGGCAGCAGTGGGGAATCTTGGACAATGGGCGCGAGCCTGATCCAGCCATGCCGCGTGAGTGAAGAAGGCCTTAGGGTTGTAAAGCTCTTTTAGCAGGGACGATAATGACGGTACCTGCAGAATAAGCCCCGGCAAACTTCGTGCCAGCAGCCGCGGTAATACGAAGGGGGCTAGCGTTGTTCGGATTTACTGGGCGTAAAGCGCACGTAGGCGGATTGTTAAGTCAGGGGTGAAATCCCGAGGCTCAACCTCGGAACTGCCTTTGATACTGGCAATCTTGAGGCTGGAAGAGGTTGGTAGAATTCCCAGTGTAGAGGTGAAATTCGTAGATATTGGGAAGAATACCAGTGGCGAGGGCGGCCAACTGGTCCAGATCTGACGCTGAGGTGCGAAAGCGTGGGGAGCAAACAGGATTAGATACCCTGGTAGTCCACGCCGTAAACTATGGGTGCTAGCCGTCAGCGGGCTTGCTCGTTGGTGGCGCAGCTAACGCATTAAGCACCCCGCCTGGGGAGTACGGTCGCAAGATTAAAACTTAAAGGAATTGACGGGGGCCCGCACAAGCGGTGGAGCATGTGGTTTAATTCGAAGCAACGCGCAGAACCTTACCTACCCTTGACATCCCGGTCGCGGACACCAGAGATGGAGTCCTTCAGTTCGGCTGGACCGGTGACAGGTGCTGCATGGCTGTCGTCAGCTCGTGTCGTGAGATGTTGGGTTAAGTCCCGCAACGAGCGCAACCCTCGCCATTAGTTGCCATCATTTAGTTGGGCACTCTAATGGGACTGCCGGTGATAAGCCGGAGGAAGGTGGGGATGACGTCAAGTCCTCATGGCCCTTACGGGTAGGGCTACACACGTGCTACAATGGCGGTGACAGAGGGCAGCTACTTCGCAAGGAGAAGCTAATCCCAAAAAGCCGTCTCAGTTCAGATTGCACTCTGCAACTCGGGTGCATGAAGTCGGAATCGCTAGTAATCGCTAATCAGCAGGTAGCGGTGAATACGTTCCCGGGCC\n",
      "Accession number: 2318640977\n",
      "Sequence from NCBI: TATTTTCCTTGTGTGCCAGCCGCCGCGGTAATACGGAGGGTGCAAGCGTTAATCGGAATCACTGGGCGTAAAGCGCACGTAGGCTGTTATGTAAGTCAGGGGTGAAATCCCACGGCTCAACCGTGGAACTGCCCTTGATACTGCACGACTTGAATCCGGGAGAGGGTGGCGGAATTCCAGGTGTAGGAGTGAAATCCGTAGATATCTGGAGGAACATCAGTGGCGAAGGCGGCCACCTGGACCGGTATTGACGCTGAGGTGCGAAAGCGTGGGGAGCAAACAGG\n",
      "Sequence from final_sequences: TATTTTCCTTGTGTGCCAGCCGCCGCGGTAATACGGAGGGTGCAAGCGTTAATCGGAATCACTGGGCGTAAAGCGCACGTAGGCTGTTATGTAAGTCAGGGGTGAAATCCCACGGCTCAACCGTGGAACTGCCCTTGATACTGCACGACTTGAATCCGGGAGAGGGTGGCGGAATTCCAGGTGTAGGAGTGAAATCCGTAGATATCTGGAGGAACATCAGTGGCGAAGGCGGCCACCTGGACCGGTATTGACGCTGAGGTGCGAAAGCGTGGGGAGCAAACAGG\n",
      "Accession number: 2432229578\n",
      "Sequence from NCBI: TTTAATGAGAGTTTGATCCTGGCTCAGGACGAACGCTGGCGGCGTGCCTAATACATGCAAGTAGAACGCTGAAGGAGGAGCTTGCTTCTCCGGATGAGTTGCGAACGGGTGAGTAACGCGTAGGTAACCTGCCTGGTAGCGGGGGATAACTATTGGAAACGATAGCTAATACCGCATAAGAGTAGATGTTGCATGACATTTGCTTAAAAGGTGCAATTGCATCACTACCAGATGGACCTGCGTTGTATTAGCTAGTTGGTGGGGTAACGGCTCACCAAGGCGACGATACATAGCCGACCTGAGAGGGTGATCGGCCACACTGGGACTGAGACACGGCCCAGACTCCTACGGGAGGCAGCAGTAGGGAATCTTCGGCAATGGACGGAAGTCTGACCGAGCAACGCCGCGTGAGTGAAGAAGGTTTTCGGATCGTAAAGCTCTGTTGTAAGAGAAGAACGAGTGTGAGAGTGGAAAGTTCACACTGTGACGGTATCTTACCAGAAAGGGACGGCTAACTACGTGCCAGCAGCCGCGGTAATACGTAGGTCCCGAGCGTTGTCCGGATTTATTGGGCGTAAAGCGAGCGCAGGCGGTTAGATAAGTCTGAAGTTAAAGGCTGTGGCTTAACCATAGTACGCTTTGGAAACTGTTTAACTTGAGTGCAAGAGGGGAGAGTGGAATTCCATGTGTAGCGGTGAAATGCGTAGATATATGGAGGAACACCGGTGGCGAAAGCGGCTCTCTGGCTTGTAACTGACGCTGAGGCTCGAAAGCGTGGGGAGCAAACAGGATTAGATACCCTGGTAGTCCACGCCGTAAACGATGAGTGCTAGGTGTTAGACCCTTTCCGGGGTTTAGTGCCGCAGCTAACGCATTAAGCACTCCGCCTGGGGAGTACGACCGCAAGGTTGAAACTCAAAGGAATTGACGGGGGCCCGCACAAGCGGTGGAGCATGTGGTTTAATTCGAAGCAACGCGAAGAACCTTACCAGGTCTTGACATCCCTCTGACCGCTCTAGAGATAGAGTTTTCCTTCGGGACAGAGGTGACAGGTGGTGCATGGTTGTCGTCAGCTCGTGTCGTGAGATGTTGGGTTAAGTCCCGCAACGAGCGCAACCCCTATTGTTAGTTGCCATCATTCAGTTGGGCACTCTAGCGAGACTGCCGGTAATAAACCGGAGGAAGGTGGGGATGACGTCAAATCATCATGCCCCTTATGACCTGGGCTACACACGTGCTACAATGGCTGGTACAACGAGTCGCAAGCCGGTGACGGCAAGCTAATCTCTTAAAGCCAGTCTCAGTTCGGATTGTAGGCTGCAACTCGCCTACATGAAGTCGGAATCGCTAGTAATCGCGGATCAGCACGCCGCGGTGAATACGTTCCCGGGCCTTGTACACACCGCCCGTCACACCACGAGAGTTTGTAACACCCGAAGTCGGTGAGGTAACCTTTTAGGAGCCAGCCGCCTAAGGTGGGATAGATGATTGGGGTGAAGTCGTAACAAGGTAGCCGTATCGGAAGGTGCGGCTGGATCACCTCCTTT\n",
      "Sequence from final_sequences: TTTAATGAGAGTTTGATCCTGGCTCAGGACGAACGCTGGCGGCGTGCCTAATACATGCAAGTAGAACGCTGAAGGAGGAGCTTGCTTCTCCGGATGAGTTGCGAACGGGTGAGTAACGCGTAGGTAACCTGCCTGGTAGCGGGGGATAACTATTGGAAACGATAGCTAATACCGCATAAGAGTAGATGTTGCATGACATTTGCTTAAAAGGTGCAATTGCATCACTACCAGATGGACCTGCGTTGTATTAGCTAGTTGGTGGGGTAACGGCTCACCAAGGCGACGATACATAGCCGACCTGAGAGGGTGATCGGCCACACTGGGACTGAGACACGGCCCAGACTCCTACGGGAGGCAGCAGTAGGGAATCTTCGGCAATGGACGGAAGTCTGACCGAGCAACGCCGCGTGAGTGAAGAAGGTTTTCGGATCGTAAAGCTCTGTTGTAAGAGAAGAACGAGTGTGAGAGTGGAAAGTTCACACTGTGACGGTATCTTACCAGAAAGGGACGGCTAACTACGTGCCAGCAGCCGCGGTAATACGTAGGTCCCGAGCGTTGTCCGGATTTATTGGGCGTAAAGCGAGCGCAGGCGGTTAGATAAGTCTGAAGTTAAAGGCTGTGGCTTAACCATAGTACGCTTTGGAAACTGTTTAACTTGAGTGCAAGAGGGGAGAGTGGAATTCCATGTGTAGCGGTGAAATGCGTAGATATATGGAGGAACACCGGTGGCGAAAGCGGCTCTCTGGCTTGTAACTGACGCTGAGGCTCGAAAGCGTGGGGAGCAAACAGGATTAGATACCCTGGTAGTCCACGCCGTAAACGATGAGTGCTAGGTGTTAGACCCTTTCCGGGGTTTAGTGCCGCAGCTAACGCATTAAGCACTCCGCCTGGGGAGTACGACCGCAAGGTTGAAACTCAAAGGAATTGACGGGGGCCCGCACAAGCGGTGGAGCATGTGGTTTAATTCGAAGCAACGCGAAGAACCTTACCAGGTCTTGACATCCCTCTGACCGCTCTAGAGATAGAGTTTTCCTTCGGGACAGAGGTGACAGGTGGTGCATGGTTGTCGTCAGCTCGTGTCGTGAGATGTTGGGTTAAGTCCCGCAACGAGCGCAACCCCTATTGTTAGTTGCCATCATTCAGTTGGGCACTCTAGCGAGACTGCCGGTAATAAACCGGAGGAAGGTGGGGATGACGTCAAATCATCATGCCCCTTATGACCTGGGCTACACACGTGCTACAATGGCTGGTACAACGAGTCGCAAGCCGGTGACGGCAAGCTAATCTCTTAAAGCCAGTCTCAGTTCGGATTGTAGGCTGCAACTCGCCTACATGAAGTCGGAATCGCTAGTAATCGCGGATCAGCACGCCGCGGTGAATACGTTCCCGGGCCTTGTACACACCGCCCGTCACACCACGAGAGTTTGTAACACCCGAAGTCGGTGAGGTAACCTTTTAGGAGCCAGCCGCCTAAGGTGGGATAGATGATTGGGGTGAAGTCGTAACAAGGTAGCCGTATCGGAAGGTGCGGCTGGATCACCTCCTTT\n",
      "Accession number: 1219553262\n",
      "Sequence from NCBI: GGGGTATATTGCACAATGGGCGAAAGCCTGATGCAGCGTCGCCGCGTGAGGGAAGATGGTTTTCGGATTGTCAACCTCTGTCTTCGGGGACGAAACAAATGACGGTACTCGAGGAGGACGCCACGGCTAACTACGTGCCAGCAGCCGCGGTAATACGTAGGGGGCTAGCGTTATCCGGATTTACTGGGCGTAAAGGGTGCGTAGGTGGTAATATGTGTCAGATGTAAAAGGCTATGGCTTAACCATAGTTAGCATTTGAAACTGTATTACTTGAGTGCAGGAGAGGTAAGTGGAAATCCTAGTGTAGCGGTGAAATGCGTAGATATTAGGAGGAACACCAGTGGCGAAGGCGACTTACTGGACTGTAACTGACGCTGAGTCACGAAAGCGTGGGTAGCAAACA\n",
      "Sequence from final_sequences: GGGGTATATTGCACAATGGGCGAAAGCCTGATGCAGCGTCGCCGCGTGAGGGAAGATGGTTTTCGGATTGTCAACCTCTGTCTTCGGGGACGAAACAAATGACGGTACTCGAGGAGGACGCCACGGCTAACTACGTGCCAGCAGCCGCGGTAATACGTAGGGGGCTAGCGTTATCCGGATTTACTGGGCGTAAAGGGTGCGTAGGTGGTAATATGTGTCAGATGTAAAAGGCTATGGCTTAACCATAGTTAGCATTTGAAACTGTATTACTTGAGTGCAGGAGAGGTAAGTGGAAATCCTAGTGTAGCGGTGAAATGCGTAGATATTAGGAGGAACACCAGTGGCGAAGGCGACTTACTGGACTGTAACTGACGCTGAGTCACGAAAGCGTGGGTAGCAAACA\n",
      "Accession number: 1985647403\n",
      "Sequence from NCBI: TACAGAGAGTGCAAGCGTTAATCGGAATTACTGGGCGTAAAGCGCACGTAGGTGGATACTTTAGTCGAATGTGAAAGCCCTGGGCTTAACCCGGGAATTGCATCCGATACTGGGTATCTAGAGTATGGTAGAGGGAAGTGGAATTTCCGGTGTAGCGGTGAAATGCGTAGATATCGGAAAGAACACCAGTGGCGAAAGCGGCTTCCTGGACCAATACTGACACTAAGGTGCGAAAGCGTGGGGAGCAAACAGG\n",
      "Sequence from final_sequences: TACAGAGAGTGCAAGCGTTAATCGGAATTACTGGGCGTAAAGCGCACGTAGGTGGATACTTTAGTCGAATGTGAAAGCCCTGGGCTTAACCCGGGAATTGCATCCGATACTGGGTATCTAGAGTATGGTAGAGGGAAGTGGAATTTCCGGTGTAGCGGTGAAATGCGTAGATATCGGAAAGAACACCAGTGGCGAAAGCGGCTTCCTGGACCAATACTGACACTAAGGTGCGAAAGCGTGGGGAGCAAACAGG\n",
      "Accession number: 2318611522\n",
      "Sequence from NCBI: TACGTAGGTCCCAAGCGTTGTCCGGATTTATTGGGCGTAAAGCGAGCGCAGGTGGTTTCTTAAGTCTGATGTAAAAGGCAGTGGCTCAACCATTGTGTGCATTGGAAACTGGGAGACTTGAGTGCAGGAGAGGAGAGTGGAATTCCATGTGTAGCGGTGAAATGCGTAGATATATGGAGGAACACCGGAGGCGAAAGCGGCTCTCTGGCCTGTAACTGACACTGAGGCTCGAAAGCGTGGGGAGCAAACAGG\n",
      "Sequence from final_sequences: TACGTAGGTCCCAAGCGTTGTCCGGATTTATTGGGCGTAAAGCGAGCGCAGGTGGTTTCTTAAGTCTGATGTAAAAGGCAGTGGCTCAACCATTGTGTGCATTGGAAACTGGGAGACTTGAGTGCAGGAGAGGAGAGTGGAATTCCATGTGTAGCGGTGAAATGCGTAGATATATGGAGGAACACCGGAGGCGAAAGCGGCTCTCTGGCCTGTAACTGACACTGAGGCTCGAAAGCGTGGGGAGCAAACAGG\n",
      "Accession number: 1962359462\n",
      "Sequence from NCBI: CTACTGGGGTATCTAATCCTGTTTGCTCCCCTAGCTTTCGTGCATCAGCGTCAGTTGTGGTCCAGTGAGCCGCTTTCGCCACAGGTGTTCCTTCCGATATCTACGCATTTCACCGCTACACCGGAAATTCCACTCACCTCTCCCACACTCAAGCCCGGCAGTATTTCGTGCAGACTTCGAGTTAAGCCCGAAGATTTCACACGAAACTTACCGAACCGCCTACGCACCCTTTACGCCCAATAATTCCGAACAACGCTCGCCCCCCTCGTATTACCGCGGCGGCTGGCAC\n",
      "Sequence from final_sequences: CTACTGGGGTATCTAATCCTGTTTGCTCCCCTAGCTTTCGTGCATCAGCGTCAGTTGTGGTCCAGTGAGCCGCTTTCGCCACAGGTGTTCCTTCCGATATCTACGCATTTCACCGCTACACCGGAAATTCCACTCACCTCTCCCACACTCAAGCCCGGCAGTATTTCGTGCAGACTTCGAGTTAAGCCCGAAGATTTCACACGAAACTTACCGAACCGCCTACGCACCCTTTACGCCCAATAATTCCGAACAACGCTCGCCCCCCTCGTATTACCGCGGCGGCTGGCAC\n",
      "Accession number: 381140139\n",
      "Sequence from NCBI: GGTTGTATGGGGGGCAGTCTGATGCAGCCATGCCGCGTGAGTGATAGAAGGCCTTCGGGTTGTAAAGCTCTTTTTTCCGGGACGATAATGACGGTGCCCCCAGAATAAACCCCGGCTAACTTCATGCCACCGCCCCCGGTAATAAAAAATGCCCCCGGCCCTATTATAATAAGACTTGTCGAGAGTCCCTTGGGGCCGTCAGATACTGGAATGCGACAAACCCCGCTTGTACCATTTTCTGAATGACCGGATTGATGTCTTCCACGCTGTCCCGGCGGTTGTGCGGGTATGCGGGAGAGTCCGTTTCATTCAGGGAGACAGGATGCGCCTGTGAGAGGTTTTTGCTGGAAGGCGATGGCCGCTGCGCTCGTATTGATCCACAGCCGGGGTCGTACGGGAGTTGGGGTGGGGATTAGTTGGGTGGGTTT\n",
      "Sequence from final_sequences: GGTTGTATGGGGGGCAGTCTGATGCAGCCATGCCGCGTGAGTGATAGAAGGCCTTCGGGTTGTAAAGCTCTTTTTTCCGGGACGATAATGACGGTGCCCCCAGAATAAACCCCGGCTAACTTCATGCCACCGCCCCCGGTAATAAAAAATGCCCCCGGCCCTATTATAATAAGACTTGTCGAGAGTCCCTTGGGGCCGTCAGATACTGGAATGCGACAAACCCCGCTTGTACCATTTTCTGAATGACCGGATTGATGTCTTCCACGCTGTCCCGGCGGTTGTGCGGGTATGCGGGAGAGTCCGTTTCATTCAGGGAGACAGGATGCGCCTGTGAGAGGTTTTTGCTGGAAGGCGATGGCCGCTGCGCTCGTATTGATCCACAGCCGGGGTCGTACGGGAGTTGGGGTGGGGATTAGTTGGGTGGGTTT\n",
      "Accession number: 1033473188\n",
      "Sequence from NCBI: CACGCCCTAAACGATGTCAACTGGTTGTTGGGTCTTCACTGACTCAGTAACGAAGCTAACGCGTGAAGTTGACCGCCTGGGGAGTACGGCCGCAAGGTTGAAACTCAAAGGAATTGACGGGGACCCGCACAAGCGGTGGATGATGTGGTTTAATTCGATGCAACGCGAAAAACCTTACCCACCTTTGACATGGCAGGAAGTTTCCAGAGATGGATTCGTGCCCGAAAGGGAACCTGCACACAGGTGC\n",
      "Sequence from final_sequences: CACGCCCTAAACGATGTCAACTGGTTGTTGGGTCTTCACTGACTCAGTAACGAAGCTAACGCGTGAAGTTGACCGCCTGGGGAGTACGGCCGCAAGGTTGAAACTCAAAGGAATTGACGGGGACCCGCACAAGCGGTGGATGATGTGGTTTAATTCGATGCAACGCGAAAAACCTTACCCACCTTTGACATGGCAGGAAGTTTCCAGAGATGGATTCGTGCCCGAAAGGGAACCTGCACACAGGTGC\n",
      "Accession number: 1219551256\n",
      "Sequence from NCBI: GGGGAATATTGGACAATGGGGGCAACCCTGATCCAGCCATGCCGCGTGAGTGAAGAAGGCCTTCGGGTTGTAAAGCTCTTTCGCAAGGGAAGAAAACGTGTGGGCTAATATCCTGCGCGGCTGACGGTACCTTGACAAGAAGCACCGGCTAACTACGTGCCAGCAGCCGCGGTAATACGTAGGGTGCGAGCGTTAATCGGAATTACTGGGCGTAAAGCGTGCGCAGGCGGTTGTGTAAGACAGGTGTGAAATCCCCGGGCTTAACCTGGGAACTGCGCTTGTGACTGCCAGGCTAGAGTACGGCAGAGGGGGGTGGAATTCCACGTGTAGCAGTGAAATGCGTAGAGATGTGGAGGAACACCGATGGCGAAGGCAGCCCCCTGGGCCGATACTGACGCTCATGCACGAAAGCGTGGGTAGCAAACA\n",
      "Sequence from final_sequences: GGGGAATATTGGACAATGGGGGCAACCCTGATCCAGCCATGCCGCGTGAGTGAAGAAGGCCTTCGGGTTGTAAAGCTCTTTCGCAAGGGAAGAAAACGTGTGGGCTAATATCCTGCGCGGCTGACGGTACCTTGACAAGAAGCACCGGCTAACTACGTGCCAGCAGCCGCGGTAATACGTAGGGTGCGAGCGTTAATCGGAATTACTGGGCGTAAAGCGTGCGCAGGCGGTTGTGTAAGACAGGTGTGAAATCCCCGGGCTTAACCTGGGAACTGCGCTTGTGACTGCCAGGCTAGAGTACGGCAGAGGGGGGTGGAATTCCACGTGTAGCAGTGAAATGCGTAGAGATGTGGAGGAACACCGATGGCGAAGGCAGCCCCCTGGGCCGATACTGACGCTCATGCACGAAAGCGTGGGTAGCAAACA\n"
     ]
    }
   ],
   "source": [
    "# Loop over the rows in check_sequences\n",
    "for i, row in sample.iterrows():\n",
    "    # Get the accession number for the current row\n",
    "    accession = row['Accession']\n",
    "    \n",
    "    # Retrieve the sequence from the NCBI database\n",
    "    sequence = get_sequence(accession)\n",
    "    \n",
    "    # Print the accession number and the sequence\n",
    "    print(f\"Accession number: {accession}\")\n",
    "    print(f\"Sequence from NCBI: {sequence}\")\n",
    "    print(f\"Sequence from final_sequences: {row['Sequence']}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### validation was suscessfull it had correctly retrieve the sequences, now I am proceeding to align the sequences\n",
    "Sequence alignment is a crucial step in comparative genomics. It allows to identify regions of similarity that may be a consequence of functional, structural, or evolutionary relationships between the sequences.  Biopython's interface can be use and use MUSCLE for sequence alignment:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before aligning I need to convert the df to a fasta file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import SeqIO\n",
    "from Bio.Seq import Seq\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "\n",
    "# Initialize an empty list to store the SeqRecord objects\n",
    "seq_records = []\n",
    "\n",
    "# Loop over the rows in the DataFrame\n",
    "for i, row in final_sequences.iterrows():\n",
    "    # Create a Seq object from the sequence string\n",
    "    seq = Seq(row['Sequence'])\n",
    "    \n",
    "    # Create a SeqRecord object from the Seq object\n",
    "    seq_record = SeqRecord(seq, id=f\"{row['GID']}_{row['Accession']}\", description='')\n",
    "    \n",
    "    # Add the SeqRecord object to the list\n",
    "    seq_records.append(seq_record)\n",
    "\n",
    "# Write the SeqRecord objects to a FASTA file\n",
    "with open(\"data/sequences.fasta\", \"w\") as output_handle:\n",
    "    SeqIO.write(seq_records, output_handle, \"fasta\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Alignment\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following snipet is just the code that I use on Colab to do the final alignment. The present PC is not robust enough to pursue the next step of alignment the sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!./muscle3.8.31_i86linux64 -in final_sequences.fasta -out /content/drive/MyDrive/aligned.fasta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking alignment correctness\n",
    "This script generates bootstrap replicates of the aligment file. The bootstrapping process should be applied to the original unaligned sequences. The idea is to generate multiple pseudo-replicated datasets from the original unaligned sequences, align each of these datasets separately, and then compare the resulting alignments. This process allows to assess the reliability of our alignment by checking how consistent the alignments are across the pseudo-replicated datasets. Also done in Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we run the alignment on each bootstrap replicate, loop over the list and run the alignment command for each file.\n",
    "# Packages needed\n",
    "from Bio import SeqIO\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "import random\n",
    "\n",
    "# Load the original sequences\n",
    "sequences = list(SeqIO.parse(\"/content/drive/MyDrive/sequences.fasta\", \"fasta\"))\n",
    "\n",
    "# Number of bootstrap replicates\n",
    "n = 100\n",
    "\n",
    "# Generate the bootstrap replicates\n",
    "for i in range(n):\n",
    "    # Generate a random sample of indices\n",
    "    indices = [random.randint(0, len(sequences)-1) for _ in range(len(sequences))]\n",
    "\n",
    "    # Create a new set of sequences from the sampled indices\n",
    "    bootstrap_sequences = [sequences[i] for i in indices]\n",
    "\n",
    "    # Write the bootstrap sequences to a new FASTA file\n",
    "    output_file = f\"/content/drive/MyDrive/replicate_new_{i}.fasta\"\n",
    "    SeqIO.write(bootstrap_sequences, output_file, \"fasta\")\n",
    "\n",
    "    # Run MUSCLE on the bootstrap replicate\n",
    "    aligned_file = f\"/content/drive/MyDrive/output_replica_new_{i}.fasta\"\n",
    "    !./muscle3.8.31_i86linux64 -in {output_file} -out {aligned_file}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing the duplicated from the bootstrap process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import SeqIO\n",
    "\n",
    "def remove_duplicates(input_file, output_file):\n",
    "    # Create a dictionary to store sequences\n",
    "    sequences = {}\n",
    "\n",
    "    # Parse the input FASTA file\n",
    "    for record in SeqIO.parse(input_file, \"fasta\"):\n",
    "        # Use the sequence identifier as the key and only keep sequences which haven't been encountered yet\n",
    "        if record.id not in sequences:\n",
    "            sequences[record.id] = record\n",
    "        else:\n",
    "            print(f\"Warning: duplicate identifier {record.id} found\")\n",
    "\n",
    "    # Write the unique sequences to a new file\n",
    "    SeqIO.write(sequences.values(), output_file, \"fasta\")\n",
    "\n",
    "# Use the function for each of your files\n",
    "for i in range(70):\n",
    "    input_file = f\"/content/drive/MyDrive/output_replica_new_{i}.fasta\"\n",
    "    output_file = f\"/content/drive/MyDrive/output_replica_no_duplicates_{i}.fasta\"\n",
    "    remove_duplicates(input_file, output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing the Replicates:\n",
    "Loading the necessary libraries and reading in the alignment files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import AlignIO\n",
    "\n",
    "# List to store the alignments\n",
    "alignments = []\n",
    "\n",
    "# Loop through the alignment files\n",
    "for i in range(70):\n",
    "    # Read the alignment file\n",
    "    alignment = AlignIO.read(f\"/content/drive/MyDrive/output_replica_no_duplicates_{i}.fasta\", \"fasta\")\n",
    "       \n",
    "    # Add the alignment to the list\n",
    "    alignments.append(alignment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we calculate the pairwise distances for each alignment and store them in a list. This will give us a measure of how similar the sequences in each aligment are to each other. The \"identity\" argument specifies to calculate the sequences number of identical positions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio.Phylo.TreeConstruction import DistanceCalculator\n",
    "\n",
    "# List to store the distance matrices\n",
    "distances = []\n",
    "\n",
    "# Loop through the alignments\n",
    "for alignment in alignments:\n",
    "    # Calculate the distance matrix\n",
    "    calculator = DistanceCalculator('identity')\n",
    "    dm = calculator.get_distance(alignment)\n",
    "    \n",
    "    # Add the distance matrix to the list\n",
    "    distances.append(dm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating the average pairwise distance for each alignment and storage it so we know the overal similarity and therefore the robusteness of the algorith of Muscle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# List to store the average distances\n",
    "average_distances = []\n",
    "\n",
    "# Loop through the distance matrices\n",
    "for dm in distances:\n",
    "    # Calculate the average distance\n",
    "    average_distance = np.mean([dm[i, j] for i in range(len(dm)) for j in range(i+1, len(dm))])\n",
    "    \n",
    "    # Add the average distance to the list\n",
    "    average_distances.append(average_distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The null hypothesis in an ANOVA is that all group means are equal.\n",
    "If the p-value is less than our chosen significance level (often 0.05), the null hypothesis had to be rejected, in other words that all group means are equal, suggesting that at least one group mean is significantly different from the others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now I will proceed to do a simple test to know if the average distances are statistically significant different. The * operator is to unpack the groups.\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Assume that average_distances is a list of lists, where each sublist is a group\n",
    "H, p_value = stats.kruskal(*average_distances)\n",
    "\n",
    "print(\"H-value:\", H)\n",
    "print(\"p-value:\", p_value)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "2.7.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
