{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cDED5j4zCqR_"
      },
      "source": [
        "# Sequence Analysis and Functional Prediction Pipeline\n",
        "This notebook is enterily run in colab\n",
        "\n",
        "## 1. Introduction\n",
        "This notebook analyzes the functional and sequence relationships between newly identified bacteria and known corrosion-influencing microorganisms. The analysis builds upon previous findings where:\n",
        "- Statistical significance was established between the selected bacteria and corrosion risk (Notebook 3)\n",
        "- Literature validation confirmed corrosion influence for many bacteria (Notebook 4)\n",
        "- Evolutionary relationships were mapped through phylogenetic analysis (Notebook 5)\n",
        "\n",
        "The study focuses on bacteria from operational heating and cooling water systems, primarily in Germany. Using 16S rRNA data (bootstrap-validated from Notebook 5), this analysis employs PICRUSt2 to predict metabolic functions and compare functional profiles between different bacterial groups.\n",
        "\n",
        "### Analysis Approaches\n",
        "We implement two classification strategies:\n",
        "\n",
        "1. Simple Classification:\n",
        "   - Known corrosion-causing bacteria (usual_taxa)\n",
        "   - Other bacteria (combining checked_taxa and core_taxa)\n",
        "\n",
        "2. Detailed Classification:\n",
        "   - Known corrosion-causing bacteria (usual_taxa)\n",
        "   - Pure checked bacteria (exclusive to checked_taxa)\n",
        "   - Pure core bacteria (exclusive to core_taxa)\n",
        "   - Checked-core bacteria (overlap between checked and core taxa)\n",
        "\n",
        "This detailed approach allows for more nuanced analysis of functional profiles and better understanding of potential corrosion mechanisms across different bacterial groups.\n",
        "\n",
        "### Analysis Goals:\n",
        "- Predict metabolic functions from 16S sequences\n",
        "- Focus on corrosion-relevant pathways (sulfur/iron metabolism)\n",
        "- Compare functional profiles between known corrosion-causing bacteria and newly identified candidates\n",
        "- Validate whether statistical correlations reflect genuine metabolic capabilities associated with corrosion processes\n",
        "\n",
        "### Directory Structure:\n",
        " Following is the structure of the notebook data named data_picrus  \n",
        "data_tree  \n",
        " â”œâ”€â”€ sequences/  \n",
        " â”‚   â”œâ”€â”€ known.fasta : sequences of known corrosion-causing bacteria  \n",
        " â”‚   â”œâ”€â”€ candidate.fasta : sequences of potential new corrosion-causing bacteria  \n",
        " |   â””â”€â”€ other files  \n",
        " data_picrus  \n",
        " â””â”€â”€ picrust_results/  \n",
        "      â”œâ”€â”€ known_bacteria/  \n",
        "      |               â”œâ”€â”€ EC_predictions/       : enzyme predictions  \n",
        "      |               â”œâ”€â”€ pathway_predictions/  : metabolic pathway abundance  \n",
        "      |               â”œâ”€â”€ KO_predictions/       : KEGG ortholog predictions  \n",
        "      |               â””â”€â”€ other_picrust_files/  \n",
        "      â”œâ”€â”€ candidate_bacteria/  \n",
        "      |               â”œâ”€â”€ EC_predictions/       : enzyme predictions  \n",
        "      |               â”œâ”€â”€ pathway_predictions/  : metabolic pathway abundance  \n",
        "      |               â”œâ”€â”€ KO_predictions/       : KEGG ortholog predictions  \n",
        "      |               â””â”€â”€ other_picrust_files/  : final comparison summary\n",
        "      â”œâ”€â”€ core_bacteria/\n",
        "      |               â”œâ”€â”€ EC_predictions/       : enzyme predictions  \n",
        "      |               â”œâ”€â”€ pathway_predictions/  : metabolic pathway abundance  \n",
        "      |               â”œâ”€â”€ KO_predictions/       : KEGG ortholog predictions  \n",
        "      |               â””â”€â”€ other_picrust_files/  \n",
        "      â”‚      \n",
        "      â””â”€â”€ functional_comparison.xlsx  \n",
        "Picrust2 works using its reference database that was installed with the package /home/beatriz/miniconda3/envs/picrust2/lib/python3.9/site-packages/picrust2/default_files/prokaryotic/pro_ref"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LeIn7RIBCqSD"
      },
      "source": [
        "# 2. Loading and Preparing the Data\n",
        "\n",
        "## 2.1 Imports, Directories, Loading and preparing the Abundance DataFrame\n",
        "The abundance DataFrame (Integrated) was carefully prepared to meet PICRUSt2 input requirements, including proper taxonomic level organization and removal of unnamed or missing data. The sequence data is sourced directly from aligned_sequences_integrated.fasta, which contains the phylogenetically aligned sequences generated in notebook 5. This integration ensures consistency between abundance data and sequence information."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing QIIME AND PICRUST IN COLAB"
      ],
      "metadata": {
        "id": "VWqOI6IDD1qW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install miniconda and initialize\n",
        "!wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh\n",
        "!bash Miniconda3-latest-Linux-x86_64.sh -b -f -p /usr/local/miniconda3\n",
        "!conda config --add channels defaults\n",
        "!conda config --add channels bioconda\n",
        "!conda config --add channels conda-forge"
      ],
      "metadata": {
        "id": "uKimriI3hmTq",
        "outputId": "c2d3cc0a-cf97-4497-b4d6-006edbaa6d82",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-01-20 16:23:21--  https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh\n",
            "Resolving repo.anaconda.com (repo.anaconda.com)... 104.16.191.158, 104.16.32.241, 2606:4700::6810:20f1, ...\n",
            "Connecting to repo.anaconda.com (repo.anaconda.com)|104.16.191.158|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 147784736 (141M) [application/octet-stream]\n",
            "Saving to: â€˜Miniconda3-latest-Linux-x86_64.shâ€™\n",
            "\n",
            "Miniconda3-latest-L 100%[===================>] 140.94M   105MB/s    in 1.3s    \n",
            "\n",
            "2025-01-20 16:23:22 (105 MB/s) - â€˜Miniconda3-latest-Linux-x86_64.shâ€™ saved [147784736/147784736]\n",
            "\n",
            "PREFIX=/usr/local/miniconda3\n",
            "Unpacking payload ...\n",
            "\n",
            "Installing base environment...\n",
            "\n",
            "Preparing transaction: ...working... done\n",
            "Executing transaction: ...working... done\n",
            "installation finished.\n",
            "WARNING:\n",
            "    You currently have a PYTHONPATH environment variable set. This may cause\n",
            "    unexpected behavior when running the Python interpreter in Miniconda3.\n",
            "    For best results, please verify that your PYTHONPATH only points to\n",
            "    directories of packages that are compatible with the Python interpreter\n",
            "    in Miniconda3: /usr/local/miniconda3\n",
            "Warning: 'conda-forge' already in 'channels' list, moving to the top\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/usr/local/miniconda3/lib/python3.7/site-packages/')\n",
        "\n",
        "# Create environment with QIIME2-2020.8 (stable version known to work with PICRUSt2)\n",
        "!conda create -n qiime2-2020.8 python=3.7 -y\n",
        "!conda activate qiime2-2020.8\n",
        "\n",
        "# Install QIIME2\n",
        "!wget https://data.qiime2.org/distro/core/qiime2-2020.8-py36-linux-conda.yml\n",
        "!conda env update -n qiime2-2020.8 --file qiime2-2020.8-py36-linux-conda.yml\n",
        "\n",
        "# Install PICRUSt2 and its dependencies\n",
        "!conda install -c bioconda -c conda-forge picrust2=2.4.1 -y"
      ],
      "metadata": {
        "id": "1TNkP-rXhutt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Verify installations\n",
        "!conda list | grep qiime2\n",
        "!conda list | grep picrust2\n",
        "\n",
        "# Function to check if the installations were successful\n",
        "def check_installations():\n",
        "    try:\n",
        "        import qiime2\n",
        "        print(\"QIIME2 installation successful\")\n",
        "        print(f\"QIIME2 version: {qiime2.__version__}\")\n",
        "    except ImportError:\n",
        "        print(\"QIIME2 installation failed\")\n",
        "\n",
        "    try:\n",
        "        !which picrust2_pipeline.py\n",
        "        print(\"PICRUSt2 installation successful\")\n",
        "    except:\n",
        "        print(\"PICRUSt2 installation failed\")\n",
        "\n",
        "check_installations()\n"
      ],
      "metadata": {
        "id": "GwAeLYHhbKaa",
        "outputId": "bb0c912b-9055-4708-a34f-6578f2fc0d83",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ¨ðŸ°âœ¨ Everything looks OK!\n",
            "Channels:\n",
            " - conda-forge\n",
            " - bioconda\n",
            "Platform: linux-64\n",
            "Collecting package metadata (repodata.json): - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\bdone\n",
            "Solving environment: | \b\bfailed\n",
            "\n",
            "SpecsConfigurationConflictError: Requested specs conflict with configured specs.\n",
            "  requested specs: \n",
            "    - python=3.6\n",
            "  pinned specs: \n",
            "    - cuda-version=12\n",
            "    - python=3.11\n",
            "    - python_abi=3.11[build=*cp311*]\n",
            "Use 'conda config --show-sources' to look for 'pinned_specs' and 'track_features'\n",
            "configuration parameters.  Pinned specs may also be defined in the file\n",
            "/usr/local/conda-meta/pinned.\n",
            "\n",
            "\n",
            "Channels:\n",
            " - bioconda\n",
            " - conda-forge\n",
            "Platform: linux-64\n",
            "Collecting package metadata (repodata.json): - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\bdone\n",
            "Solving environment: - \b\b\\ \b\b| \b\b/ \u001b[33m\u001b[1mwarning  libmamba\u001b[m Added empty dependency for problem type SOLVER_RULE_UPDATE\n",
            "\b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\bfailed\n",
            "\n",
            "LibMambaUnsatisfiableError: Encountered problems while solving:\n",
            "  - package pandas-0.25.3-py36hb3f55d8_0 requires python >=3.6,<3.7.0a0, but none of the providers can be installed\n",
            "\n",
            "Could not solve for environment specs\n",
            "The following packages are incompatible\n",
            "â”œâ”€ \u001b[32mpandas 0.25.3** \u001b[0m is installable with the potential options\n",
            "â”‚  â”œâ”€ \u001b[32mpandas 0.25.3\u001b[0m would require\n",
            "â”‚  â”‚  â””â”€ \u001b[32mpython >=3.6,<3.7.0a0 \u001b[0m, which can be installed;\n",
            "â”‚  â”œâ”€ \u001b[32mpandas 0.25.3\u001b[0m would require\n",
            "â”‚  â”‚  â””â”€ \u001b[32mpython >=3.7,<3.8.0a0 \u001b[0m, which can be installed;\n",
            "â”‚  â””â”€ \u001b[32mpandas 0.25.3\u001b[0m would require\n",
            "â”‚     â””â”€ \u001b[32mpython >=3.8,<3.9.0a0 \u001b[0m, which can be installed;\n",
            "â””â”€ \u001b[31mpin-2\u001b[0m is not installable because it requires\n",
            "   â””â”€ \u001b[31mpython 3.11** \u001b[0m, which conflicts with any installable versions previously reported.\n",
            "\n",
            "Requirement already satisfied: q2-picrust2 in /usr/local/lib/python3.11/site-packages (2024.5)\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/picrust2_pipeline.py\", line 15, in <module>\n",
            "    from picrust2.pipeline import full_pipeline\n",
            "  File \"/usr/local/lib/python3.11/site-packages/picrust2/pipeline.py\", line 17, in <module>\n",
            "    from picrust2.metagenome_pipeline import run_metagenome_pipeline\n",
            "  File \"/usr/local/lib/python3.11/site-packages/picrust2/metagenome_pipeline.py\", line 12, in <module>\n",
            "    from pandas.util.testing import assert_frame_equal\n",
            "ModuleNotFoundError: No module named 'pandas.util.testing'\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'qiime2'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-f08b5599dd63>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# Import and test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mqiime2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"QIIME2 installed successfully\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'qiime2'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Example usage with test data\n",
        "# Download test data\n",
        "!wget http://kronos.pharmacology.dal.ca/public_files/picrust/picrust2_tutorial_files/mammal_biom.qza\n",
        "!wget http://kronos.pharmacology.dal.ca/public_files/picrust/picrust2_tutorial_files/mammal_seqs.qza\n",
        "\n",
        "# Run PICRUSt2 through QIIME2\n",
        "!qiime picrust2 full-pipeline \\\n",
        "    --i-table mammal_biom.qza \\\n",
        "    --i-seq mammal_seqs.qza \\\n",
        "    --output-dir q2-picrust2_output \\\n",
        "    --p-placement-tool sepp \\\n",
        "    --p-threads 1 \\\n",
        "    --p-hsp-method pic \\\n",
        "    --p-max-nsti 2 \\\n",
        "    --verbose\n",
        "\n",
        "# Function to analyze the output\n",
        "def check_output():\n",
        "    import os\n",
        "    output_files = os.listdir('q2-picrust2_output')\n",
        "    print(\"Generated output files:\")\n",
        "    for file in output_files:\n",
        "        print(f\"- {file}\")\n",
        "\n",
        "check_output()\n",
        "\n",
        "\"\"\"\n",
        "Instructions for using this notebook:\n",
        "\n",
        "1. Create a new Colab notebook\n",
        "2. Copy this entire code into the notebook\n",
        "3. Run the cells in order\n",
        "4. The installation may take 5-10 minutes\n",
        "5. After installation, you can use QIIME2 and PICRUSt2 commands\n",
        "\n",
        "Common troubleshooting:\n",
        "- If you get memory errors, try restarting the runtime\n",
        "- Make sure to run cells in order\n",
        "- Check that all installations completed successfully\n",
        "- If you get path errors, make sure conda environment is activated\n",
        "\n",
        "To use your own data:\n",
        "1. Upload your feature table (.qza format)\n",
        "2. Upload your sequence file (.qza format)\n",
        "3. Modify the PICRUSt2 command with your file names\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "iv6OFDj1U1J9",
        "outputId": "339038b8-6579-4f19-8559-805d36de0e25",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: qiime: command not found\n",
            "/bin/bash: line 1: qiime: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Fm8oknVuDWTL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "#change the path\n",
        "os.chdir('/content/drive/My Drive/MIC/picrust')"
      ],
      "metadata": {
        "id": "qYcLDQCGK7Yd",
        "outputId": "b8147437-4b51-4355-d378-dfc7f446435f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'os' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-c0dcc3ef8375>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#change the path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/My Drive/MIC/picrust'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Verify QIIME2 installation\n",
        "import qiime2\n",
        "print(qiime2.__version__)"
      ],
      "metadata": {
        "id": "XPLgSV7iWTk9",
        "outputId": "018f4b4a-c513-42d2-d10c-05cb3cef8865",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 368
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'qiime2'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-543b80f94fdc>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Verify QIIME2 installation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mqiime2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqiime2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'qiime2'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "l92DnCZ3CqSD",
        "outputId": "f06a6ae0-ba43-4924-bfff-eafa8d6008ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 405
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'Bio'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-438090cc860b>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mio\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStringIO\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpathlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mBio\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSeqIO\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPhylo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Data processing imports\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'Bio'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "# Standard library imports\n",
        "import condacolab\n",
        "import os\n",
        "import ast\n",
        "from io import StringIO\n",
        "from pathlib import Path\n",
        "from Bio import SeqIO, Phylo\n",
        "\n",
        "# Data processing imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import openpyxl\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# BIOM handling\n",
        "from biom import Table\n",
        "from biom.util import biom_open\n",
        "\n",
        "# Add QIIME2 specific imports\n",
        "import qiime2\n",
        "from qiime2.plugins import feature_table"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vd9eCDzzKm4T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jhg73Rb9CqSF"
      },
      "outputs": [],
      "source": [
        "# Directory Structure Definitions\n",
        "SIMPLE_BASE = {\n",
        "    'known': 'simple_known_mic',\n",
        "    'other': 'simple_candidate_mic'\n",
        "}\n",
        "\n",
        "DETAILED_BASE = {\n",
        "    'known': 'detailed_known_mic',\n",
        "    'pure_checked': 'detailed_pure_checked_mic',\n",
        "    'pure_core': 'detailed_pure_core_mic',\n",
        "    'checked_core': 'detailed_checked_core_mic'\n",
        "}\n",
        "\n",
        "SUBDIRS = [\n",
        "    'EC_predictions',\n",
        "    'pathway_predictions',\n",
        "    'KO_predictions',\n",
        "    'other_picrust_files'\n",
        "]\n",
        "\n",
        "# Base Paths\n",
        "base_dir = Path(\"/home/beatriz/MIC/2_Micro/data_picrust\")\n",
        "# Create output directory if it doesn't exist\n",
        "base_dir.mkdir(parents=True, exist_ok=True)\n",
        "aligned_file = Path(\"/home/beatriz/MIC/2_Micro/data_qiime/qiime_aligned_sequences.fasta/aligned-dna-sequences.fasta\")\n",
        "abundance_excel = Path(\"/home/beatriz/MIC/2_Micro/data_Ref/merged_to_sequence.xlsx\")\n",
        "results_file = base_dir / \"functional_comparison.xlsx\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zy30BkzOCqSG"
      },
      "outputs": [],
      "source": [
        "# Read fasta file\n",
        "aligned_sequences = list(SeqIO.parse(aligned_file, \"fasta\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "COW1kGFZCqSG"
      },
      "source": [
        "Main dataframe come from the merged dataframe of name 'core_check_usual_taxa' coming from the directory /home/beatriz/MIC/2_Micro/data_Ref/merged_to_sequence.xlsx, 'sheet_name='core_check_usual_taxa',  it was cleaned, then it was groupby on dataframes that reflected the source where came from, the known bacteria were groupby from the sources: 'chk-core-us', 'chk-us', 'core-us', 'us'. The core group pure_core come from core_taxa, column core. The checked group pure_checked come from checked_taxa column chck. The group check_core was made for the combination of core_taxa and checked_genera column chck_core. The final proccesed dataframe is called Integrated and is clened up from the taxonomical levels, the Source and Category columns are keep appart. Then Integrate df has only the identifiers GIDs as index, the sites as headers and the values on floats corresponding to the abundance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0GfxFOJzCqSG"
      },
      "outputs": [],
      "source": [
        "# Integrated taxa from origin genus as headers with levels 6 for the genera, 7 for the GID, muss be cleaned\n",
        "Integrated_T = pd.read_excel(abundance_excel, sheet_name='core_check_usual_taxa', header=[0,1,2,3,4,5,6,7])\n",
        "# Drop first row (index 0) and first column in one chain\n",
        "Integrated_T = Integrated_T.drop(index=0).drop(Integrated_T.columns[0], axis=1)\n",
        "# Remove 'Unnamed' level names\n",
        "Integrated_T.columns = Integrated_T.columns.map(lambda x: tuple('' if 'Unnamed' in str(level) else level for level in x))\n",
        "# If the dataframe has Nan in sites it will replace it with Source\n",
        "Integrated_T['Sites'] = Integrated_T['Sites'].fillna('Source')\n",
        "# Fill the other index with nothing\n",
        "Integrated_T =  Integrated_T.fillna(' ')\n",
        "Integrated_T= Integrated_T.set_index(\"Sites\")\n",
        "pre_Integrated = Integrated_T.T\n",
        "# sources are  array([' ', 'chk-core', 'chk', 'chk-core-us', 'chk-us', 'core-us', 'core', 'us'], dtype=object)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MWukq8fUCqSH"
      },
      "outputs": [],
      "source": [
        "def process_integrated_data(df):\n",
        "    \"\"\"\n",
        "    Process the integrated DataFrame to create a new DataFrame with clear column names\n",
        "    and preserve all values including source information.\n",
        "\n",
        "    Parameters:\n",
        "    df (pandas.DataFrame): Input DataFrame with MultiIndex index and site columns\n",
        "\n",
        "    Returns:\n",
        "    pandas.DataFrame: Processed DataFrame with clear structure\n",
        "    \"\"\"\n",
        "\n",
        "    # Extract genera and GIDs from the index MultiIndex\n",
        "    genera = df.index.get_level_values(6)[1:]  # Skip first row\n",
        "    gids = pd.to_numeric(df.index.get_level_values(7)[1:], errors='coerce')\n",
        "\n",
        "    # Create a new DataFrame with the extracted information\n",
        "    result_df = pd.DataFrame({\n",
        "        'Genus': genera,\n",
        "        'GID': gids\n",
        "    })\n",
        "\n",
        "    # Add the site values from the original DataFrame\n",
        "    for col in df.columns:\n",
        "        result_df[col] = df.iloc[1:][col].values\n",
        "\n",
        "    # Clean up the DataFrame\n",
        "    result_df['GID'] = pd.to_numeric(result_df['GID'], errors='coerce')\n",
        "    result_df = result_df.dropna(subset=['GID'])\n",
        "    result_df['GID'] = result_df['GID'].astype(int)\n",
        "\n",
        "    return result_df\n",
        "\n",
        "def get_taxa_groups(df):\n",
        "    \"\"\"\n",
        "    Separate the processed DataFrame into different taxa groups based on Source column\n",
        "\n",
        "    Parameters:\n",
        "    df (pandas.DataFrame): Processed DataFrame from process_integrated_data()\n",
        "\n",
        "    Returns:\n",
        "    dict: Dictionary containing DataFrames for different taxa groups\n",
        "    \"\"\"\n",
        "    # Split the data into groups based on 'Source' column patterns\n",
        "\n",
        "    # Known corrosion bacteria (any pattern with 'us')\n",
        "    known_bacteria = df[df['Source'].str.contains('us', case=False, na=False)]\n",
        "\n",
        "    # Pure checked bacteria (only 'chk' without 'core' or 'us')\n",
        "    pure_checked = df[\n",
        "        df['Source'].str.contains('chk', case=False, na=False) &\n",
        "        ~df['Source'].str.contains('core|us', case=False, na=False)\n",
        "    ]\n",
        "\n",
        "    # Pure core bacteria (only 'core' without 'chk' or 'us')\n",
        "    pure_core = df[\n",
        "        df['Source'].str.contains('core', case=False, na=False) &\n",
        "        ~df['Source'].str.contains('chk|us', case=False, na=False)\n",
        "    ]\n",
        "\n",
        "    # Checked-core bacteria (contains both 'core' and 'chk' but no 'us')\n",
        "    checked_core = df[\n",
        "        df['Source'].str.contains('chk.*core|core.*chk', case=False, na=False) &\n",
        "        ~df['Source'].str.contains('us', case=False, na=False)\n",
        "    ]\n",
        "\n",
        "    # Create groups dictionary\n",
        "    taxa_groups = {\n",
        "        'known_bacteria': known_bacteria,\n",
        "        'pure_checked': pure_checked,\n",
        "        'pure_core': pure_core,\n",
        "        'checked_core': checked_core\n",
        "    }\n",
        "\n",
        "    # Print summary statistics\n",
        "    print(\"\\nDetailed Classification Results:\")\n",
        "    print(f\"Known corrosion bacteria: {len(known_bacteria)}\")\n",
        "    print(f\"Pure checked bacteria: {len(pure_checked)}\")\n",
        "    print(f\"Pure core bacteria: {len(pure_core)}\")\n",
        "    print(f\"Checked-core bacteria: {len(checked_core)}\")\n",
        "\n",
        "    # Verify total matches expected\n",
        "    total_classified = len(known_bacteria) + len(pure_checked) + len(pure_core) + len(checked_core)\n",
        "    print(f\"\\nTotal classified taxa: {total_classified}\")\n",
        "    print(f\"Total in dataset: {len(df)}\")\n",
        "\n",
        "    return taxa_groups\n",
        "\n",
        "# Usage example:\n",
        "Integrated = process_integrated_data(pre_Integrated)\n",
        "\n",
        "# Get the groups\n",
        "taxa_groups = get_taxa_groups(Integrated)\n",
        "\n",
        "# Access individual groups -\n",
        "known_bacteria = taxa_groups['known_bacteria']\n",
        "pure_core = taxa_groups['pure_core']\n",
        "pure_checked = taxa_groups['pure_checked']\n",
        "checked_core = taxa_groups['checked_core']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aGA-_PFjCqSH"
      },
      "source": [
        "Some bacterial genera were excluded from the analysis due to unavailable reference sequences, primarily affecting rare species. The following genera were removed: Clostridium_sensu_stricto_12, Oxalobacteraceae_unclassified, Psb-m-3, Ruminiclostridium_1, and Wchb1-05. As demonstrated in Section 2.3, the statistical analysis of the BIOM-formatted data confirmed that the removal of these genera did not significantly impact the overall results of this study."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DLCZy23uCqSH"
      },
      "outputs": [],
      "source": [
        "# List of genera to remove\n",
        "genera_to_remove = {'Clostridium_sensu_stricto_12', 'Oxalobacteraceae_unclassified',\n",
        "                   'Psb-m-3', 'Ruminiclostridium_1', 'Wchb1-05'}\n",
        "\n",
        "# Filter out the rows where Genus column matches any of the genera in the list\n",
        "Integrated= Integrated [~Integrated ['Genus'].isin(genera_to_remove)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w6mUJ2IoCqSI"
      },
      "source": [
        "optional"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1cyW6Ov2CqSI"
      },
      "outputs": [],
      "source": [
        "# Ensure the genera_to_remove set is correctly defined\n",
        "genera_to_remove = {'Clostridium_sensu_stricto_12', 'Oxalobacteraceae_unclassified',\n",
        "                    'Psb-m-3', 'Ruminiclostridium_1', 'Wchb1-05'}\n",
        "\n",
        "# Convert genera_to_remove to a set of strings\n",
        "genera_to_remove = set(str(genus) for genus in genera_to_remove)\n",
        "\n",
        "# Now try the filtering again\n",
        "Integrated = Integrated[~Integrated['Genus'].isin(genera_to_remove)]\n",
        "\n",
        "# Check if any rows were removed\n",
        "print(f\"Rows in dataframe: {len(Integrated)}\")\n",
        "\n",
        "# Check if any of the genera to remove are still present\n",
        "remaining_genera = set(Integrated['Genus']) & genera_to_remove\n",
        "if remaining_genera:\n",
        "    print(f\"These genera are still present: {remaining_genera}\")\n",
        "else:\n",
        "    print(\"All specified genera have been removed successfully.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wiTB_uA5CqSI"
      },
      "outputs": [],
      "source": [
        "# droping source and genus and putting GID as index\n",
        "pre_biom= Integrated.drop(columns=[\"Source\", \"GID\"])\n",
        "pre_biom= pre_biom.set_index(\"Genus\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IzeV0ZGzCqSI"
      },
      "outputs": [],
      "source": [
        "pre_biom.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8rTVDMqICqSJ"
      },
      "source": [
        "Having the cleaned structure for Biom transformation, follows the formatting\n",
        "## 2.2. Formatting Integrated df to Biom table to QIIME artifact\n",
        "It creates a table with GID/OTUS as index, Sites as headers, abundance values and saves it as abundance.biom ultimately transforming it to QIIME format."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gkW3aSroCqSJ"
      },
      "outputs": [],
      "source": [
        "# Create BIOM table\n",
        "biom_table = Table(\n",
        "    data= pre_biom.values,\n",
        "    observation_ids=pre_biom.index.astype(str),  # GID strings\n",
        "    sample_ids=pre_biom.columns.astype(str) ,  # Sites as sample IDs\n",
        ")\n",
        "\n",
        "# Write to file\n",
        "output_biom = \"/home/beatriz/MIC/2_Micro/data_picrust/abundance.biom\"\n",
        "with biom_open(output_biom, 'w') as f:\n",
        "    biom_table.to_hdf5(f, \"Abundance data in BIOM format\")\n",
        "\n",
        "# Verify BIOM file\n",
        "print(f\"BIOM file created: {output_biom}\")\n",
        "print(f\"Number of observations: {biom_table.shape[0]}\")\n",
        "print(f\"Number of samples: {biom_table.shape[1]}\")\n",
        "\n",
        "# Convert BIOM to QIIME2 artifact\n",
        "table_artifact = qiime2.Artifact.import_data(\n",
        "    'FeatureTable[Frequency]',\n",
        "    output_biom\n",
        ")\n",
        "# Verify QIIME2 artifact\n",
        "print(\"\\nQIIME2 Artifact Info:\")\n",
        "print(f\"Type: {table_artifact.type}\")\n",
        "print(f\"UUID: {table_artifact.uuid}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E25C6EHKCqSJ"
      },
      "source": [
        "Looking at the table how is formed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vyiKYIQOCqSJ"
      },
      "outputs": [],
      "source": [
        "# Load and check the BIOM file\n",
        "from biom import load_table\n",
        "biom_table = load_table(\"/home/beatriz/MIC/2_Micro/data_picrust/abundance.biom\")\n",
        "print(biom_table)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dtsXFiQxCqSJ"
      },
      "outputs": [],
      "source": [
        "!biom summarize-table -i /home/beatriz/MIC/2_Micro/data_picrust/abundance.biom"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z5ZEkxANCqSJ"
      },
      "source": [
        "Sumarising the counts of the samples (Sites) and the observations (genera) in the previous cell. This represent statistics, include values like min and max mean and median counts per sample. The raw data provided by the studied as mencioned everywhere else represents relative abundances. The majority of your samples (~98%) are normalized so that their total abundance sums to 99-100%, as expected for datasets providing relative abundances. 70 samples are to 100-99% abundance relative percentage. 10 of them are less than 99%. Two of them are 89 and 87% this diferences could be due to normalisation artifacts, rounding or truncation. Also if the technicians filtered out rare or low-abundance taxa to clean the dataset, those exclusions may account for totals less than 100%. Samples with higher proportions of these filtered taxa might show a bigger drop. This is for the raw percentages, Now the biom statistics reflex other view of the data, the following statistics were done for the whole 84 features/observations/genera:\n",
        "\n",
        "Num samples: 70\n",
        "Num observations: 84\n",
        "Total count: 5630\n",
        "Table density (fraction of non-zero values): 0.406\n",
        "\n",
        "Counts/sample summary:\n",
        " Min: 18.180\n",
        " Max: 99.058\n",
        " Median: 84.819\n",
        " Mean: 80.439\n",
        " Std. dev.: 16.000\n",
        " Sample Metadata Categories: None provided\n",
        " Observation Metadata Categories: None provided\n",
        "\n",
        "Counts/sample detail:\n",
        "site_69: 18.180\n",
        "site_67: 21.790\n",
        "site_70: 27.060\n",
        "site_13: 54.982\n",
        "site_26: 58.300\n",
        "site_21: 58.973\n",
        "site_5: 60.650\n",
        "\n",
        "The Statistics seen in this biom table could be read as low intensity (0.406) and indicates that more than half the taxa have zero counts for most samples, consistent with a dataset dominated by a few taxa. Counts/sample summary is calculated by relative abundances and site_69 shows very low count, that maybe explained by an uneven distribution of taxa (highly skewed abundances, few dominant taxa or/and technical issues during sample preparation or sequencing). Other possible explanations for the low density of the samples 69,67,70 could be that they are the very sites with missing taxa and it is noticed during the evaluation of the sequences. However close inspection of the sites: site_40 has 77% of sequences been removed by concept of removing Clostridium_sensu_stricto_12, because the sequence was no get from the NCBI nor elsewhere and however this site shows a count ratio of 91.21 %. Same site when removed these missing genera from the data, shows a very low relative abundance which is expected since 73% was removed by no sequenciating the Clostridium sensu stricto 12. Site_31 has a percentage of 55,35 of Oxalobacteraceae_unclassified which has been also removed. Sites 12,38 and 65, has been remove between 8-14% by concept of removing Psb-m-3 bacteria.  Sites 20 and 41 has been removed between 11-18% sequences when removing Ruminiclostridium_1 bacteria. Site 12 has removed Wchb1-0 bacteria which accounted for 20% of the abundance of the site. However the fact that this removals are not being reflected on the statistical summary is a good signal that those genera were no relevant for the community as they do not belong to any of the here studied groups of genera core_taxa, checked_genera or usual_taxa. Instead the percentages are reflecting that on site_69, there is few of our selected genera and hence the representation is very low. In conclusion sites site_69, site_67 and site_70 have different community compositions than the others, with fewer of your target bacteria present, which is no a surprise since those sites come from UK sites."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ctRmZwVECqSK"
      },
      "source": [
        "# Removing the genera and replacing the accension numbers for PICRUST2 Database"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nLlbhJt0CqSK"
      },
      "outputs": [],
      "source": [
        "# Input file from previous QIIME2 alignment\n",
        "input_file = Path(\"data_qiime/qiime_aligned_sequences.fasta/aligned-dna-sequences.fasta\")\n",
        "\n",
        "# Intermediate file with cleaned headers\n",
        "clean_headers_file = Path('data_qiime/clean_headers.fasta')\n",
        "\n",
        "# Create output directory for masked alignment\n",
        "masked_output_dir = Path(\"data_qiime/masked_sequences\")\n",
        "masked_output_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Clean the headers\n",
        "cleaned_records = []\n",
        "for record in SeqIO.parse(input_file, \"fasta\"):\n",
        "    accession = record.description.split('Accession:')[1].strip()\n",
        "    new_record = SeqRecord(\n",
        "        seq=record.seq,\n",
        "        id=accession,\n",
        "        description=\"\"\n",
        "    )\n",
        "    cleaned_records.append(new_record)\n",
        "\n",
        "# Write cleaned sequences\n",
        "SeqIO.write(cleaned_records, clean_headers_file, \"fasta\")\n",
        "\n",
        "# Import cleaned sequences into QIIME2\n",
        "aligned_artifact = qiime2.Artifact.import_data(\n",
        "    'FeatureData[AlignedSequence]',\n",
        "    str(clean_headers_file)\n",
        ")\n",
        "\n",
        "# Apply masking\n",
        "masked_alignment = alignment.methods.mask(\n",
        "    alignment=aligned_artifact,\n",
        "    max_gap_frequency=0.5,\n",
        "    min_conservation=0.4\n",
        ")\n",
        "\n",
        "# Export masked alignment to directory\n",
        "masked_alignment.masked_alignment.export_data(str(masked_output_dir))\n",
        "\n",
        "# The resulting file will be in a new directory with QIIME2's default name\n",
        "print(f\"Pipeline steps:\")\n",
        "print(f\"1. Input aligned sequences: {input_file}\")\n",
        "print(f\"2. Cleaned headers file: {clean_headers_file}\")\n",
        "print(f\"3. Masked alignment output: {masked_output_dir}/aligned-dna-sequences.fasta\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HclWYTLrCqSK"
      },
      "source": [
        "## 2.4. Optimising the Sequences by Trimming and Cleaning\n",
        "\n",
        "The focus is to preserve the most informative diagnostic regions, maintain alignment within these regions. Care is taken on keeping the phylogenetic relationships intact so that the picrust analysis be of better quality, mantaining the biological significance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MF3-K5hbCqSK"
      },
      "outputs": [],
      "source": [
        "def optimize_diagnostic_sequences(input_fasta, output_fasta):\n",
        "    \"\"\"\n",
        "    Optimize sequences preserving key diagnostic regions\n",
        "    \"\"\"\n",
        "    # Key diagnostic regions we want to preserve\n",
        "    key_regions = [\n",
        "        (249, 572),   # Large region 1\n",
        "        (934, 1653),  # Largest region\n",
        "        (2344, 2846)  # Large region 2\n",
        "    ]\n",
        "\n",
        "    sequences = {}\n",
        "    current_header = \"\"\n",
        "\n",
        "    print(\"Reading sequences...\")\n",
        "    with open(input_fasta) as f:\n",
        "        for line in f:\n",
        "            line = line.strip()\n",
        "            if line.startswith('>'):\n",
        "                current_header = line\n",
        "                sequences[current_header] = []\n",
        "            elif line:\n",
        "                sequences[current_header].append(line)\n",
        "\n",
        "    # Join sequences\n",
        "    for header in sequences:\n",
        "        sequences[header] = ''.join(sequences[header])\n",
        "\n",
        "    # Find optimal boundaries that include key regions\n",
        "    start_pos = min(region[0] for region in key_regions)\n",
        "    end_pos = max(region[1] for region in key_regions)\n",
        "\n",
        "    print(f\"\\nOptimized boundaries:\")\n",
        "    print(f\"Start: {start_pos}\")\n",
        "    print(f\"End: {end_pos}\")\n",
        "\n",
        "    # Write optimized sequences\n",
        "    print(\"\\nWriting optimized sequences...\")\n",
        "    with open(output_fasta, 'w') as out:\n",
        "        for header, seq in sequences.items():\n",
        "            trimmed_seq = seq[start_pos:end_pos]\n",
        "            non_gaps = sum(1 for c in trimmed_seq if c != '-')\n",
        "            content_ratio = non_gaps / len(trimmed_seq)\n",
        "\n",
        "            out.write(f\"{header}\\n\")\n",
        "            for i in range(0, len(trimmed_seq), 60):\n",
        "                out.write(trimmed_seq[i:i+60] + '\\n')\n",
        "\n",
        "            print(f\"Sequence {header.split()[0]} content ratio: {content_ratio:.2%}\")\n",
        "\n",
        "    print(f\"\\nProcessing complete:\")\n",
        "    print(f\"Original length: {len(next(iter(sequences.values())))}\")\n",
        "    print(f\"Optimized length: {end_pos - start_pos}\")\n",
        "    print(f\"Sequences processed: {len(sequences)}\")\n",
        "\n",
        "# Run the optimization\n",
        "aligned_file = Path(\"/home/beatriz/MIC/2_Micro/data_tree/aligned_sequences_integrate.fasta\")\n",
        "output_file = aligned_file.parent / \"diagnostic_optimized_sequences.fasta\"\n",
        "optimize_diagnostic_sequences(aligned_file, output_file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C6WJh60DCqSK"
      },
      "source": [
        "There are high quality (>50%): Hydrogenophaga (53.60%), Blastomonas (59.38%), Phenylobacterium (52.87%), Afipia (57.91%), Neisseria (55.99%), Desulfovibrio (60.95%), Acetobacterium (57.87%), Bulleidia (51.75%). The moderate quality (35-50%): About 35 sequences, including Nitrospira, Oerskovia, most Proteobacteria. Also we found low quality (<25%): About 20 sequences, including Corynebacterium (16.67%), Treponema (24.53%), Variovorax (16.90%), Desulfobulbus (16.71%).\n",
        "Regarding sequence Length, the original sequences have 3471 bases and by optimising they are left about 2597 bases. That makes a 75% of the original length, and this regions are quality diagnostic regions. Base on this realities two approach will be taken, run picrust2 on high >50% quality qusequences and second compare result s with low quality sequences. However this approach will sacrify some of the bacteria that may have no quality sequences but are relevant for out study.  Therefore it is important to check the quality quality distribution within our groups. We make consider to use different quality threshold so that we can barging on the results.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f7lKM5qdCqSK"
      },
      "outputs": [],
      "source": [
        "def verify_cleaned_sequences(fasta_file):\n",
        "    \"\"\"\n",
        "    Verify the quality of cleaned sequences\n",
        "    \"\"\"\n",
        "    sequences = {}\n",
        "    current_header = \"\"\n",
        "\n",
        "    print(\"Analyzing cleaned sequences...\")\n",
        "    with open(fasta_file) as f:\n",
        "        for line in f:\n",
        "            line = line.strip()\n",
        "            if line.startswith('>'):\n",
        "                current_header = line\n",
        "                sequences[current_header] = []\n",
        "            elif line:\n",
        "                sequences[current_header].append(line)\n",
        "\n",
        "    # Join sequences and analyze\n",
        "    for header in sequences:\n",
        "        sequences[header] = ''.join(sequences[header])\n",
        "\n",
        "    # Calculate statistics\n",
        "    lengths = []\n",
        "    base_counts = []\n",
        "\n",
        "    for header, seq in sequences.items():\n",
        "        lengths.append(len(seq))\n",
        "        base_counts.append(sum(1 for c in seq if c != '-'))\n",
        "\n",
        "    print(f\"\\nSequence Statistics:\")\n",
        "    print(f\"Total sequences: {len(sequences)}\")\n",
        "    print(f\"Sequence length: {lengths[0]} (all sequences same length)\")\n",
        "    print(f\"Average non-gap bases: {sum(base_counts)/len(base_counts):.1f}\")\n",
        "    print(f\"Min non-gap bases: {min(base_counts)}\")\n",
        "    print(f\"Max non-gap bases: {max(base_counts)}\")\n",
        "\n",
        "# Verify the cleaned sequences\n",
        "output_file = aligned_file.parent / \"picrust_ready_sequences.fasta\" #\"diagnostic_optimized_sequences.fasta\" # \"picrust_ready_sequences.fasta\"\n",
        "verify_cleaned_sequences(output_file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gG41UVKQCqSK"
      },
      "source": [
        "Using verify_cleaned_sequences run over **\"diagnostic_optimises_sequences.fasta\"** which has 2597 bp length (better content), was found that: Total sequences: 79 Sequence length: 2597 (all sequences same length) Average non-gap bases: 937.5 Min non-gap bases: 433 Max non-gap bases: 1583. Using the **\"picrust_ready_sequences.fasta\"** which has 890 bp length (more aggressive trimming)was found: Total sequences: 79 Sequence length: 890 (all sequences same length) Average non-gap bases: 314.0, Min non-gap bases: 96 Max non-gap bases: 588. In average the first trimming diadnostic optimised version has better content with  937.5 average non-gap bases, in contrast to  314.0 non-gap bases, which appears to be too aggressive. The first cleaning-triming preserves more sequence content, removes unnecesary gaps, yet mantainig the important diagnostic regions. On the other hand the groupby analysis show similar quality patterns for all."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6X6KJ-w_CqSL"
      },
      "source": [
        "## Biom Data Replacing Genera with Accession Numbers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pggxoyFgCqSL"
      },
      "outputs": [],
      "source": [
        "# First recreate the mapping to make sure we have it\n",
        "fasta_mapping = {}\n",
        "with open(input_fasta) as f:\n",
        "    for record in SeqIO.parse(f, \"fasta\"):\n",
        "        genus = record.description.split()[0]\n",
        "        accession = record.description.split('Accession:')[1].strip()\n",
        "        fasta_mapping[genus] = accession\n",
        "\n",
        "# Load current BIOM table\n",
        "biom_table = load_table(\"/home/beatriz/MIC/2_Micro/data_picrust/abundance.biom\")\n",
        "\n",
        "# Get the observation IDs (currently genera)\n",
        "obs_ids = biom_table.ids(axis='observation')\n",
        "\n",
        "# Create new IDs using the mapping\n",
        "new_ids = [fasta_mapping[obs_id] for obs_id in obs_ids]\n",
        "\n",
        "# Create new BIOM table with accession numbers\n",
        "acce_biom = Table(\n",
        "    data=biom_table.matrix_data,\n",
        "    observation_ids=new_ids,\n",
        "    sample_ids=biom_table.ids()\n",
        ")\n",
        "\n",
        "# Save new BIOM file\n",
        "with biom_open('/home/beatriz/MIC/2_Micro/data_picrust/abundance_accession.biom', 'w') as f:\n",
        "    acce_biom.to_hdf5(f, \"Abundance data with accession numbers\")\n",
        "\n",
        "print(\"New BIOM file created with accession numbers as IDs\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mKnDSmd-CqSL"
      },
      "source": [
        "# Fasta Mapping and Accession as ID\n",
        "It appears that picrust doesnt take genus nor gid numbers but accession numbers, so in order to be able to compare those, it is necesary to map the accession numers to the gids to the genera and let the fasta data just with the identifiers accession which is the ones that picrust2 database uses."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IphBewO7CqSL"
      },
      "outputs": [],
      "source": [
        "# First create the mapping\n",
        "fasta_mapping = {}\n",
        "with open(aligned_file) as f:\n",
        "    for line in f:\n",
        "        if line.startswith('>'):\n",
        "            # Parse header like \"Nitrospira Accession:1197011011\"\n",
        "            genus = line.split()[0][1:]  # Remove '>' and get genus\n",
        "            accession = line.split('Accession:')[1].strip()\n",
        "            fasta_mapping[genus] = accession\n",
        "\n",
        "# Now we can use this mapping to update both files\n",
        "print(\"Sample of genus to accession mapping:\")\n",
        "for genus, accession in list(fasta_mapping.items())[:5]:\n",
        "    print(f\"{genus}: {accession}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I9sldVQuCqSL"
      },
      "outputs": [],
      "source": [
        "# Input and output paths\n",
        "input_fasta = Path(\"/home/beatriz/MIC/2_Micro/data_tree/diagnostic_optimized_sequences.fasta\")\n",
        "output_fasta = Path(\"/home/beatriz/MIC/2_Micro/data_tree/accession_sequences.fasta\")\n",
        "\n",
        "clean_fasta_with_accessions(input_fasta, output_fasta)\n",
        "\n",
        "def clean_fasta_with_accessions(input_fasta, output_fasta):\n",
        "    \"\"\"\n",
        "    Clean FASTA headers to use accession numbers as IDs\n",
        "    \"\"\"\n",
        "    cleaned_records = []\n",
        "    with open(input_fasta) as f:\n",
        "        for record in SeqIO.parse(f, \"fasta\"):\n",
        "            # Get accession from description\n",
        "            accession = record.description.split('Accession:')[1].strip()\n",
        "            # Create new record with accession as ID\n",
        "            new_record = SeqRecord(\n",
        "                seq=record.seq,\n",
        "                id=accession,\n",
        "                name=accession,\n",
        "                description=\"\"\n",
        "            )\n",
        "            cleaned_records.append(new_record)\n",
        "\n",
        "    # Write cleaned sequences\n",
        "    SeqIO.write(cleaned_records, output_fasta, \"fasta\")\n",
        "    print(f\"Created clean FASTA file with {len(cleaned_records)} sequences\")\n",
        "\n",
        "    # Show first few headers to verify\n",
        "    print(\"\\nFirst few headers in cleaned file:\")\n",
        "    for record in cleaned_records[:3]:\n",
        "        print(f\">{record.id}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zDoEX3odCqSM"
      },
      "source": [
        "Reversing the sequence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sURb0XZaCqSM"
      },
      "outputs": [],
      "source": [
        "input_fasta = Path(\"/home/beatriz/MIC/2_Micro/data_tree/accession_sequences.fasta\")\n",
        "output_fasta = Path(\"/home/beatriz/MIC/2_Micro/data_tree/accession_revers_seq.fasta\")\n",
        "\n",
        "# Use an f-string to format the command with the correct file paths\n",
        "command = f\"seqtk seq -r {input_fasta} > {output_fasta}\"\n",
        "\n",
        "# Use subprocess to run the command\n",
        "import subprocess\n",
        "subprocess.run(command, shell=True, check=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tcGbxoHPCqSM"
      },
      "source": [
        "Comparing our data with the database data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sfx_I_eTCqSM"
      },
      "outputs": [],
      "source": [
        "# our data\n",
        "# Replace 'input_sequences.fasta' with your actual input file name\n",
        "for record in SeqIO.parse(\"/home/beatriz/MIC/2_Micro/data_tree/accession_sequences.fasta\", \"fasta\"):\n",
        "    print(f\">{record.id}\")\n",
        "    print(record.seq[:150])  # Print first 50 bases of each sequence"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r3rpslI8CqSM"
      },
      "source": [
        "# Database Data from picrust"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DS54uGz7CqSM"
      },
      "outputs": [],
      "source": [
        "# Check first few entries of PICRUSt2's reference database\n",
        "with open('/home/beatriz/miniconda3/envs/picrust2/lib/python3.9/site-packages/picrust2/default_files/prokaryotic/pro_ref/pro_ref.fna') as f:\n",
        "    print(\"First few lines of PICRUSt2 reference database:\")\n",
        "    for i, line in enumerate(f):\n",
        "        print(line.strip())\n",
        "        if i > 10:  # Print first few lines only\n",
        "            break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zv-yUkfmCqSN"
      },
      "source": [
        "## 2.6. Classifying Bacteria by their Source DataFrame\n",
        "Two distinct classification approaches are implemented to categorize bacteria. The simple approach (get_bacteria_sources_simple) divides bacteria into known corrosion-causers (usual_taxa) and candidates (all others). The detailed approach (get_bacteria_sources_detailed) provides finer categorization by separating bacteria into known corrosion-causers, pure checked taxa, pure core taxa, and those present in both checked and core datasets. Please notice that this function uses df Integrated for source clasification and no abundance.biom which will be used for the picrust2 pipeline."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5bDVrPwWCqSR"
      },
      "outputs": [],
      "source": [
        "def get_bacteria_sources_simple(Integrated_df):\n",
        "    \"\"\"\n",
        "    Simple classification:\n",
        "    1. Known (anything with 'us')\n",
        "    2. All others (combined chk, core, chk-core)\n",
        "    \"\"\"\n",
        "    # Get genera and gids from column levels 6 and 7\n",
        "    genera = Integrated_df[\"Genus\"]\n",
        "    gids = Integrated_df[\"GID\"]\n",
        "    # Look for Source in the data, not index\n",
        "    sources = Integrated_df['Source'] if 'Source' in Integrated_df.columns else None\n",
        "\n",
        "    known_bacteria = {}     # usual_taxa\n",
        "    other_bacteria = {}     # everything else\n",
        "\n",
        "    sources_found = set()\n",
        "    source ={}\n",
        "    patterns = ['us', 'core-us', 'chk-us', 'chk-core-us']\n",
        "\n",
        "    for i, (genus, gid) in enumerate (zip(genera, gids)):\n",
        "        if source is not None:  # Check if source exists for this genus\n",
        "            source = str(sources.iloc[i]).strip().lower()\n",
        "            sources_found.add(source)\n",
        "\n",
        "            if source in patterns:\n",
        "                known_bacteria[genus] = int(gid) if str(gid).isdigit() else gid\n",
        "            else:\n",
        "                other_bacteria[genus] = int(gid) if str(gid).isdigit() else gid\n",
        "\n",
        "    print(\"\\nSimple Classification Results:\")\n",
        "    print(f\"Known corrosion bacteria: {len(known_bacteria)}\")\n",
        "    print(f\"Other bacteria: {len(other_bacteria)}\")\n",
        "    print(\"\\nSources found:\", sources_found)\n",
        "\n",
        "    return {\n",
        "        'known_bacteria': known_bacteria,\n",
        "        'other_bacteria': other_bacteria\n",
        "    }\n",
        "\n",
        "def get_bacteria_sources_detailed(Integrated_df):\n",
        "    \"\"\"\n",
        "    Detailed classification with all possible combinations:\n",
        "    1. Known (usual_taxa)\n",
        "    2. Pure checked (only 'chk')\n",
        "    3. Pure core (only 'core')\n",
        "    4. Checked-core (overlap 'chk-core')\n",
        "    \"\"\"\n",
        "    # Get genera and gids from column levels 6 and 7\n",
        "    genera = Integrated_df.index.get_level_values(6)[1:]\n",
        "    gids = Integrated_df.index.get_level_values(7)[1:]\n",
        "\n",
        "    sources = Integrated_df['Source'] if 'Source' in Integrated_df.columns else None\n",
        "\n",
        "    known_bacteria = {}      # usual_taxa\n",
        "    pure_checked = {}        # only 'chk' checked_taxa\n",
        "    pure_core = {}          # only 'core' core_taxa\n",
        "    checked_core = {}       # 'chk-core' checked and core taxa\n",
        "    source ={}\n",
        "    sources_found = set()\n",
        "    patterns = ['us', 'core-us', 'chk-us', 'chk-core-us']\n",
        "\n",
        "    for i, (genus, gid) in enumerate (zip(genera, gids)):\n",
        "        if source is not None:  # Check if source exists for this genus\n",
        "            source = str(sources.iloc[i]).strip().lower()\n",
        "            sources_found.add(source)\n",
        "\n",
        "            if source in patterns:\n",
        "                known_bacteria[genus] = int(gid) if str(gid).isdigit() else gid\n",
        "                continue\n",
        "\n",
        "            # Then handle other combinations\n",
        "            if source == 'chk':\n",
        "                pure_checked[genus] = gid\n",
        "            elif source == 'core':\n",
        "                pure_core[genus] = gid\n",
        "            elif 'chk-core' in source:\n",
        "                checked_core[genus] = gid\n",
        "\n",
        "    print(\"\\nDetailed Classification Results:\")\n",
        "    print(f\"Known corrosion bacteria: {len(known_bacteria)}\")\n",
        "    print(f\"Pure checked bacteria: {len(pure_checked)}\")\n",
        "    print(f\"Pure core bacteria: {len(pure_core)}\")\n",
        "    print(f\"Checked-core bacteria: {len(checked_core)}\")\n",
        "    print(\"\\nSources found:\", sources_found)\n",
        "\n",
        "    return {\n",
        "        'known_bacteria': known_bacteria,\n",
        "        'pure_checked': pure_checked,\n",
        "        'pure_core': pure_core,\n",
        "        'checked_core': checked_core\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "23P2k1QwCqSR"
      },
      "source": [
        "## 2.7. Prepare picrust data and Creating Directories for PICRUSt2 Input\n",
        "The check_missing_genera function processes the integrated data and handles data quality control. Known problematic genera (e.g., 'Clostridium_sensu_stricto_12', 'Oxalobacteraceae_unclassified') are flagged for exclusion to prevent analysis errors. The function also creates an organized directory structure as outlined in the introduction, with separate paths for different bacterial classifications (known_mic, candidate_mic, etc.) and their respective analysis outputs (EC_predictions, pathway_predictions, KO_predictions). Following function prepares the data for picrust analysis but both dataframes the abundance.biom and Integrated have some bacteria that were no sequenciated mostly cause are no known specimens. So it is necesary to do same procedure to both dfs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bNfnbXfKCqSS"
      },
      "outputs": [],
      "source": [
        "def prepare_picrust_data(Integrated_df, aligned_file, function_type='simple'):\n",
        "    \"\"\"\n",
        "    Prepare data for PICRUSt analysis with choice of  function_type method\n",
        "\n",
        "    Args:\n",
        "        Integrated_df: Input DataFrame\n",
        "        aligned_file: Path to aligned sequences\n",
        "        function_type: 'simple' or 'detailed'\n",
        "    \"\"\"\n",
        "    # Get bacteria source_groups based on chosen  function_type\n",
        "    if  function_type == 'simple':\n",
        "        source_groups = get_bacteria_sources_simple(Integrated_df)\n",
        "    else:\n",
        "        source_groups= get_bacteria_sources_detailed(Integrated_df)\n",
        "\n",
        "    # Create appropriate directory structure\n",
        "    create_directory_structure(function_type)\n",
        "\n",
        "    return source_groups\n",
        "\n",
        "def create_directory_structure(function_type='simple'):\n",
        "    \"\"\"Create directory structure for PICRUSt analysis\"\"\"\n",
        "    base_dir = Path(\"/home/beatriz/MIC/2_Micro/data_picrust\")\n",
        "\n",
        "    if function_type == 'simple':\n",
        "        directories = SIMPLE_BASE\n",
        "    else:\n",
        "        directories = DETAILED_BASE\n",
        "\n",
        "    # Create all required directories\n",
        "    for dir_name in directories.values():\n",
        "        for subdir in SUBDIRS:\n",
        "            (base_dir / dir_name / subdir).mkdir(parents=True, exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RUwADMKZCqSS"
      },
      "source": [
        "# 3. PICRUSt Pipeline Definition\n",
        "The pipeline processes the aligned sequence data from notebook 5 that has or not undergo cleaning of the sequences as previously done on section 2. Also processes the biom_table in order to account on this anylsis on abundance. It queries the PICRUSt database to predict potential metabolic pathways for each genus. This prediction is based on evolutionary relationships and known genomic capabilities of related organisms."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "srMpS5DkCqSS"
      },
      "outputs": [],
      "source": [
        "def run_picrust2_pipeline(fasta_file, biom_file, output_dir):\n",
        "    \"\"\"\n",
        "    Run the main PICRUSt2 pipeline on input sequences and BIOM table.\n",
        "\n",
        "    Args:\n",
        "        fasta_file: Path to the aligned sequences FASTA file.\n",
        "        biom_file: Path to the BIOM table (without extra columns).\n",
        "        output_dir: Directory for PICRUSt2 output.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Run main PICRUSt2 pipeline\n",
        "        cmd = [\n",
        "            'picrust2_pipeline.py',\n",
        "            '-s', fasta_file,        # Input FASTA file with aligned sequences\n",
        "            '-i', biom_file,         # BIOM table with abundance data\n",
        "            '-o', output_dir,        # Output directory\n",
        "            '--processes', '4',      # Parallel processes\n",
        "            '--verbose',\n",
        "            '--min_align', '0.25'    # Note the split here\n",
        "        ]\n",
        "        subprocess.run(cmd, check=True)\n",
        "\n",
        "        # Add pathway descriptions if the pathway file exists\n",
        "        pathway_file = os.path.join(output_dir, 'pathways_out/path_abun_unstrat.tsv.gz')\n",
        "        if os.path.exists(pathway_file):\n",
        "            cmd_desc = [\n",
        "                'add_descriptions.py',\n",
        "                '-i', pathway_file,\n",
        "                '-m', 'PATHWAY',\n",
        "                '-o', os.path.join(output_dir, 'pathways_with_descriptions.tsv')\n",
        "            ]\n",
        "            subprocess.run(cmd_desc, check=True)\n",
        "\n",
        "        print(f\"PICRUSt2 pipeline completed successfully for {output_dir}\")\n",
        "        return True\n",
        "\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        print(f\"Error running PICRUSt2: {e}\")\n",
        "        return False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rx_DyzHbCqSS"
      },
      "source": [
        "# 4. Analysis of Pathways\n",
        "The analysis focuses on metabolic pathways known to be involved in microbially influenced corrosion, including sulfur metabolism, organic acid production, iron metabolism, and biofilm formation. These pathways were selected based on documented mechanisms of known corrosion-inducing bacteria. Separate pipeline runs for simple and detailed classifications ensure proper pathway analysis for each bacterial group."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8eP8MAidCqSS"
      },
      "outputs": [],
      "source": [
        "def analyze_functional_profiles(picrust_output_dir, bacteria_list):\n",
        "    \"\"\"\n",
        "    Analyze functional profiles with focus on corrosion-relevant pathways\n",
        "\n",
        "    Parameters:\n",
        "    picrust_output_dir: directory containing PICRUSt2 output\n",
        "    bacteria_list: list of bacteria names to analyze\n",
        "    \"\"\"\n",
        "    # Define corrosion-relevant pathways\n",
        "    relevant_pathways = [\n",
        "        'Sulfur metabolism',\n",
        "        'Iron metabolism',\n",
        "        'Energy metabolism',\n",
        "        'Biofilm formation',\n",
        "        'Metal transport',\n",
        "        'ochre formation',\n",
        "        'iron oxide deposits',\n",
        "        'iron precipitation',\n",
        "        'rust formation',\n",
        "        'organic acid production',\n",
        "        'acetate production',\n",
        "        'lactate metabolism',\n",
        "        'formate production',\n",
        "    ]\n",
        "\n",
        "    try:\n",
        "        # Read PICRUSt2 output\n",
        "        pathway_file = os.path.join(picrust_output_dir, 'pathways_with_descriptions.tsv')\n",
        "        pathways_df = pd.read_csv(pathway_file, sep='\\t')\n",
        "\n",
        "        # Filter for relevant pathways\n",
        "        filtered_pathways = pathways_df[\n",
        "            pathways_df['description'].str.contains('|'.join(relevant_pathways),\n",
        "                                                  case=False,\n",
        "                                                  na=False)]\n",
        "\n",
        "        # Calculate pathway abundances per bacteria\n",
        "        pathway_abundances = filtered_pathways.groupby('description').sum()\n",
        "\n",
        "        # Calculate pathway similarities between bacteria\n",
        "        pathway_similarities = {}\n",
        "        for bacteria in bacteria_list:\n",
        "            if bacteria in pathways_df.columns:\n",
        "                similarities = pathways_df[bacteria].corr(pathways_df[list(bacteria_list)])\n",
        "                pathway_similarities[bacteria] = similarities\n",
        "\n",
        "        # Predict functional potential\n",
        "        functional_predictions = {}\n",
        "        for pathway in relevant_pathways:\n",
        "            pathway_presence = filtered_pathways[\n",
        "                filtered_pathways['description'].str.contains(pathway, case=False)\n",
        "            ]\n",
        "            if not pathway_presence.empty:\n",
        "                functional_predictions[pathway] = {\n",
        "                    'presence': len(pathway_presence),\n",
        "                    'mean_abundance': pathway_presence.mean().mean(),\n",
        "                    'max_abundance': pathway_presence.max().max()\n",
        "                }\n",
        "\n",
        "        # Calculate correlation scores\n",
        "        correlation_scores = {}\n",
        "        for bacteria in bacteria_list:\n",
        "            if bacteria in pathways_df.columns:\n",
        "                correlations = pathways_df[bacteria].corr(\n",
        "                    pathways_df[filtered_pathways.index]\n",
        "                )\n",
        "                correlation_scores[bacteria] = {\n",
        "                    'mean_correlation': correlations.mean(),\n",
        "                    'max_correlation': correlations.max(),\n",
        "                    'key_pathways': correlations.nlargest(5).index.tolist()\n",
        "                }\n",
        "\n",
        "        comparison_results = {\n",
        "            'pathway_similarities': pathway_similarities,\n",
        "            'functional_predictions': functional_predictions,\n",
        "            'correlation_scores': correlation_scores,\n",
        "            'pathway_abundances': pathway_abundances.to_dict()\n",
        "        }\n",
        "\n",
        "        return filtered_pathways, comparison_results\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error in pathway analysis: {str(e)}\")\n",
        "        return None, None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i-EEla9jCqSS"
      },
      "source": [
        "# Testing the pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mnwckS6sCqST"
      },
      "outputs": [],
      "source": [
        "# ---- RUNNING THE PIPELINE ----\n",
        "\n",
        "# Set paths\n",
        "aligned_fasta_file = Path('/home/beatriz/MIC/2_Micro/data_tree/accession_sequences.fasta') #'data_tree/aligned_sequences_integrate.fasta')\n",
        "abundance_biom_file =  Path('/home/beatriz/MIC/2_Micro/data_picrust/abundance_accession.biom')\n",
        "output_dir = 'picrust9_output'\n",
        "\n",
        "# List of bacteria to analyze\n",
        "bacteria_of_interest = ['Azospira', 'Brachybacterium', 'Bulleidia']\n",
        "\n",
        "# Run PICRUSt2\n",
        "if run_picrust2_pipeline(aligned_fasta_file,\n",
        "                         abundance_biom_file,\n",
        "                         output_dir\n",
        "                        ):\n",
        "    # Analyze functional profiles if the pipeline completes successfully\n",
        "    filtered_pathways, abundances = analyze_functional_profiles(output_dir, bacteria_of_interest)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "03KIf3UaCqST"
      },
      "source": [
        "# 5. Functional Analysis\n",
        "The analysis workflow begins by categorizing bacteria into source groups using the classification functions. These categorized data are then processed through the PICRUSt pipeline to predict metabolic capabilities. The functional analysis examines pathway presence, abundance, and correlations between different bacterial groups to identify potential corrosion-related metabolic patterns."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uHpbek-BCqST"
      },
      "outputs": [],
      "source": [
        "def run_functional_analysis(df, Integrated_df, aligned_file, analysis_type='simple'):\n",
        "    \"\"\"\n",
        "    Run complete functional analysis pipeline for either simple or detailed classification\n",
        "\n",
        "    Parameters:\n",
        "    df: Input DataFrame\n",
        "    aligned_file: Path to aligned sequences file\n",
        "    analysis_type: 'simple' or 'detailed'\n",
        "    \"\"\"\n",
        "    try:\n",
        "        print(f\"\\n{'='*50}\")\n",
        "        print(f\"Starting {analysis_type} classification analysis\")\n",
        "        print(f\"{'='*50}\")\n",
        "\n",
        "        # Prepare data and get source groups\n",
        "        print(\"\\nStep 1: Preparing data...\")\n",
        "\n",
        "        source_groups = prepare_picrust_data(Integrated_df, aligned_file, function_type=analysis_type)\n",
        "\n",
        "        if not source_groups:\n",
        "            raise ValueError(\"Failed to prepare data: No source groups returned\")\n",
        "\n",
        "        # Base directory for PICRUSt output\n",
        "        base_dir = Path(\"/home/beatriz/MIC/2_Micro/data_picrust\")\n",
        "\n",
        "        results = {}\n",
        "\n",
        "        if analysis_type == 'simple':\n",
        "            # Run analysis for simple classification\n",
        "            # Known bacteria\n",
        "            known_output_dir = base_dir /SIMPLE_BASE['known']\n",
        "            success_known = run_picrust2_pipeline(aligned_file, df, str(known_output_dir))\n",
        "            if success_known:\n",
        "                results_known = analyze_functional_profiles(str(known_output_dir),\n",
        "                                                        source_groups['known_bacteria'].keys())\n",
        "\n",
        "            # Other bacteria\n",
        "            other_output_dir = base_dir / SIMPLE_BASE['other']\n",
        "            success_other = run_picrust2_pipeline(aligned_file, str(other_output_dir))\n",
        "            if success_other:\n",
        "                results_other = analyze_functional_profiles(str(other_output_dir),\n",
        "                                                        source_groups['other_bacteria'].keys())\n",
        "\n",
        "        else:\n",
        "            # Run analysis for detailed classification\n",
        "            for group, dir_name in DETAILED_BASE.items():\n",
        "\n",
        "                # Known bacteria\n",
        "                known_output_dir = base_dir / DETAILED_BASE['known']\n",
        "                success_known = run_picrust2_pipeline(aligned_file, str(known_output_dir))\n",
        "                if success_known:\n",
        "                    results_known = analyze_functional_profiles(str(known_output_dir),\n",
        "                                                            source_groups['known_bacteria'].keys())\n",
        "\n",
        "                # Pure checked bacteria\n",
        "                checked_output_dir = base_dir /  DETAILED_BASE['pure_checked']\n",
        "                success_checked = run_picrust2_pipeline(aligned_file, str(checked_output_dir))\n",
        "                if success_checked:\n",
        "                    results_checked = analyze_functional_profiles(str(checked_output_dir),\n",
        "                                                            source_groups['pure_checked'].keys())\n",
        "\n",
        "                # Pure core bacteria\n",
        "                core_output_dir = base_dir /DETAILED_BASE['pure_core']\n",
        "                success_core = run_picrust2_pipeline(aligned_file, str(core_output_dir))\n",
        "                if success_core:\n",
        "                    results_core = analyze_functional_profiles(str(core_output_dir),\n",
        "                                                            source_groups['pure_core'].keys())\n",
        "\n",
        "                # Checked-core bacteria\n",
        "                checked_core_output_dir = base_dir /DETAILED_BASE['checked_core']\n",
        "                success_checked_core = run_picrust2_pipeline(aligned_file, str(checked_core_output_dir))\n",
        "                if success_checked_core:\n",
        "                    results_checked_core = analyze_functional_profiles(str(checked_core_output_dir),\n",
        "                                                                    source_groups['checked_core'].keys())\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        print(f\"Error running PICRUSt2: {e}\")\n",
        "\n",
        "        return \"Analysis completed successfully\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-CP-vb-uCqST"
      },
      "source": [
        "diagnostic_optimized_sequences.fasta, picrust_ready_sequences.fasta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3NyEekbBCqST"
      },
      "outputs": [],
      "source": [
        "# Run the analysis for both types\n",
        "# Simple source classification\n",
        "simple_results = run_functional_analysis(biom_table, aligned_file, analysis_type='simple') # output_biom\n",
        "\n",
        "# Detailed source classification\n",
        "detailed_results = run_functional_analysis(biom_table, aligned_file, analysis_type='detailed')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X4rP1kdUCqST"
      },
      "source": [
        "# 6. Findings and Discusion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5A2a1CNLCqSW"
      },
      "outputs": [],
      "source": [
        "def run_picrust2_pipeline(fasta_file, output_dir, min_align =0.5):\n",
        "    \"\"\"\n",
        "    Run PICRUSt2 pipeline with improved error handling and path management\n",
        "\n",
        "    Args:\n",
        "        fasta_file: Path to aligned sequences fasta file (str or Path)\n",
        "        output_dir: Directory for PICRUSt2 output (str or Path)\n",
        "    \"\"\"\n",
        "    import subprocess\n",
        "    import os\n",
        "    from pathlib import Path\n",
        "\n",
        "    # Convert paths to strings\n",
        "    fasta_file = str(fasta_file)\n",
        "    output_dir = str(output_dir)\n",
        "\n",
        "    try:\n",
        "        # Verify picrust2 is available\n",
        "        picrust_check = subprocess.run(['which', 'picrust2_pipeline.py'],\n",
        "                                     capture_output=True,\n",
        "                                     text=True)\n",
        "        if picrust_check.returncode != 0:\n",
        "            raise RuntimeError(\"picrust2_pipeline.py not found. Please ensure PICRUSt2 is properly installed.\")\n",
        "\n",
        "        # Create output directory\n",
        "        os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "        # Construct command as a single string\n",
        "        cmd = f\"picrust2_pipeline.py -s {fasta_file} -i {fasta_file} -o {output_dir} --processes 1 --verbose\"\n",
        "\n",
        "        # Run pipeline\n",
        "        print(f\"Running command: {cmd}\")\n",
        "        process = subprocess.run(cmd,\n",
        "                               shell=True,  # Use shell to handle command string\n",
        "                               check=True,\n",
        "                               capture_output=True,\n",
        "                               text=True)\n",
        "\n",
        "        print(\"PICRUSt2 Output:\")\n",
        "        print(process.stdout)\n",
        "\n",
        "        if process.stderr:\n",
        "            print(\"Warnings/Errors:\")\n",
        "            print(process.stderr)\n",
        "\n",
        "        # Add descriptions if pathway file exists\n",
        "        pathway_file = os.path.join(output_dir, 'pathways_out/path_abun_unstrat.tsv.gz')\n",
        "        if os.path.exists(pathway_file):\n",
        "            desc_cmd = f\"add_descriptions.py -i {pathway_file} -m PATHWAY -o {os.path.join(output_dir, 'pathways_with_descriptions.tsv')}\"\n",
        "            subprocess.run(desc_cmd, shell=True, check=True)\n",
        "\n",
        "        print(f\"PICRUSt2 pipeline completed successfully for {output_dir}\")\n",
        "        return True\n",
        "\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        print(f\"Error running PICRUSt2 command: {e}\")\n",
        "        print(f\"Command output: {e.output}\")\n",
        "        return False\n",
        "    except Exception as e:\n",
        "        print(f\"Error in pipeline: {str(e)}\")\n",
        "        return False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hbhd5NNkCqSX"
      },
      "outputs": [],
      "source": [
        "# For original sequences\n",
        "aligned_file = Path(\"/home/beatriz/MIC/2_Micro/data_tree/aligned_sequences_integrate.fasta\")\n",
        "output_dir = Path(\"/home/beatriz/MIC/2_Micro/data_picrust/original_results\")\n",
        "success = run_picrust2_pipeline(aligned_file, output_dir)\n",
        "\n",
        "# For improved sequences\n",
        "optimized_file = Path(\"/home/beatriz/MIC/2_Micro/data_tree/picrust_optimized_sequences.fasta\")\n",
        "optimized_output = Path(\"/home/beatriz/MIC/2_Micro/data_picrust/optimized_results\")\n",
        "success_opt = run_picrust2_pipeline(optimized_file, optimized_output)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python (QIIME2)",
      "language": "python",
      "name": "qiime2-2023.7"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.15"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}