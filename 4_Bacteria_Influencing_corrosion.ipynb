{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 1. Bacteria Influencing Corrosion\n",
        "This notebook aims to identify microorganisms that have a recognized influence on corrosion damage. The analysis involves comparing bacteria against known corrosion-related gene sequences and metabolic pathways associated with Microbiologically Influenced Corrosion (MIC).\n",
        "__Aims__\n",
        "Search literature on the study selected genera that have been reported as causing corrosion damage, using different terms. Make a comprehensive tabel of the results. Comprehensive search on specific functional genes involved in corrosion processes, focusing on: Sulfate reduction pathways (dsrAB, aprAB genes),metal reduction genes and cytochrome c3 complexes. \n",
        "Perform targeted analysis between known corrosion-causing bacteria and newly identified bacterial specimens\n",
        "\n",
        "__Databases Used__:\n",
        "    * KEGG (Kyoto Encyclopedia of Genes and Genomes): https://www.genome.jp/kegg/pathway.html.Used for metabolic pathway identification and functional gene annotations  \n",
        "    * PubMed: Used for literature analysis and validation. \n",
        "__Analysis Workflow__    \n",
        "1. Initial Computational Screening → Search KEGG database for pathways and genes →Literature validation through PubMed \n",
        "2. Results Analysis and Documentation → Compilation of findings in Excel sheets → Documentation of references and abstracts\n",
        "Notebook files\n",
        "Copy/home/beatriz/MIC/2_Micro/data_Ref/\n",
        "├── bacteria_corrosion_summary_{timestamp}.xlsx    # Results file for each run\n",
        "│   ├── Analysis_{timestamp}    # Main results sheet\n",
        "│   ├── References             # APA formatted references\n",
        "│   └── Abstracts             # Related paper abstracts\n",
        "└── Original_data/            # Raw data storage"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GCsQTfwH1vwT"
      },
      "source": [
        "# 1. Bacteria Influencing Corrosion\n",
        "This notebook has as objective to dilucidate which of the microorganisms in the data have recognised influence in corrosion damage. With this pool of bacteria we compare the nobel bacteria here found with the gene sequences of the known corrosion-related genes belonging to MIC or the metabolic pathways are related or can be related to corrosion. Then using the list here found as \"anchors\" to find associated bacteria\n",
        "Looking for similar metabolic patterns in other species no yet related to MIC.\n",
        "## Aims\n",
        " __ Compare specific functional genes known to be involved in corrosion processes, particularly        focusing on sulfate reduction pathways (dsrAB, aprAB genes),Metal reduction genes, Cytochrome c3 complexes\n",
        "__Perform targeted comparative genomic analysis between known corrosion-causing bacteria\n",
        "  newly identified bacterial specimens from this research\n",
        "\n",
        "The databases uses on this notebook are:\n",
        "\n",
        "Bacmet: 'https://bacmet.biomedicine.gu.se/download.html',\n",
        "KEGG : 'https://www.genome.jp/kegg/pathway.html', which is the Kyoto Encyclopedia of Genes and Genomes. With this is possible to find metabolic pathways, identify functional gene annotations\n",
        "IMG/M: 'https://img.jgi.doe.gov/',- For detailed metabolic pathways\n",
        "BRENDA: 'https://www.brenda-enzymes.org/\n",
        "\n",
        "1. Initial Computational Screening  --> 1a. search_all_databases -->1b. analyze_metabolic_pathways \n",
        "   ↓                                                                 ↓\n",
        "2. Literature Validation                           <--- 1c. Literature Analysis    \n",
        "   ↓   \n",
        "3. Metabolic Pathway Analysis and mapping- PICRUSt2 - Can predict metabolic functions from 16S data   \n",
        "   ↓    \n",
        "4. Find functional similarities between known and candidate bacteria, compare taxonomic groups with similar functional profiles   \n",
        "   ↓    \n",
        "5. Sequence analysis for: Sulfate reduction genes, Iron metabolism genes, Biofilm    formation genes\n",
        "   ↓    \n",
        "6. Identify gene clusters associated with iron metabolism   \n",
        "    \n",
        "Structure of the notebook: /home/beatriz/MIC/2_Micro/data_Ref/   \n",
        "├── bacteria_corrosion_summary.xlsx    # Main results file with multiple sheets   \n",
        "|________________________________________               ↓    \n",
        "|  ______________________________________  Results, references and Abstract    \n",
        "|   \n",
        "├── Original_data/                     # For the total data   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lmqm_cyo26JA",
        "outputId": "17a0d832-53c2-44ae-d1d0-75346521374a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"import os\\nfrom google.colab import drive  #silence for vscode\\ndrive.mount('/content/drive')\\n#change the path\\nos.chdir('/content/drive/My Drive/MIC')\\n# For colab\\n!pip install pandas numpy biopython\\n!pip install requests beautifulsoup4\\n!pip install Bio\""
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''import os\n",
        "from google.colab import drive  #silence for vscode\n",
        "drive.mount('/content/drive')\n",
        "#change the path\n",
        "os.chdir('/content/drive/My Drive/MIC')\n",
        "# For colab\n",
        "!pip install pandas numpy biopython\n",
        "!pip install requests beautifulsoup4\n",
        "!pip install Bio'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fYZMXODQ1vwV"
      },
      "source": [
        "# 2. Preparing data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "f1SdK88z1vwV"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "from Bio import Entrez\n",
        "import pandas as pd\n",
        "from functools import partial\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import time\n",
        "import urllib3\n",
        "from datetime import datetime\n",
        "import logging\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import openpyxl\n",
        "from openpyxl.styles import Alignment\n",
        "import gc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\\nfrom google.colab import drive\\ndrive.mount(\\'/content/drive\\')\\nbase_dir = Path(\\'/content/drive/My Drive/MIC/data\\')\\noriginal_dir = base_dir / \"original\"\\noriginal_dir.mkdir(exist_ok=True)\\n'"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# For VSCode\n",
        "base_dir = Path(\"/home/beatriz/MIC/2_Micro/data_Ref\")\n",
        "original_dir = base_dir / \"Original_data\"\n",
        "Literatur_dir = base_dir / \"References\"\n",
        "results_file = base_dir / \"bacteria_corrosion_summary.xlsx\" \n",
        "\n",
        "# For Colab\n",
        "'''\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "base_dir = Path('/content/drive/My Drive/MIC/data')\n",
        "original_dir = base_dir / \"original\"\n",
        "original_dir.mkdir(exist_ok=True)\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "l8B5GWW01vwW"
      },
      "outputs": [],
      "source": [
        "# Read the Excel file for the whole data\n",
        "Jointax = pd.read_excel(\"data/Jointax.xlsx\", sheet_name='Biotot_jointax', header=[0,1,2,3,4,5,6,7])\n",
        "# Drop 2 first columns\n",
        "Jointax = Jointax.drop(Jointax.columns[0:2], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Read the Excel file for the checked genera\n",
        "selected = pd.read_excel(\"/home/beatriz/MIC/2_Micro/data/finalist_dfs.xlsx\", sheet_name='checked_genera', header=[0,1,2,3,4,5,6,7])\n",
        "# Drop first row specifically (index 0 which contains NaNs)\n",
        "selected = selected.drop(index=0)\n",
        "# Drop first column (the index column with Level1, Level2, etc)\n",
        "selected = selected.drop(selected.columns[0:3], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "selected_list = selected.columns.get_level_values(6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Extract Genera and ID from the multi-index, For selected genera\n",
        "selected_GID = dict(zip(selected.columns.get_level_values(6), selected.columns.get_level_values(7)))\n",
        "# For all genera \n",
        "all_GID = dict(zip(Jointax.columns.get_level_values(6), Jointax.columns.get_level_values(7)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 3. Reference Formating Function\n",
        "Following function is to take the references given in the search and present them on APA style list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "def format_apa_reference(article):\n",
        "    \"\"\"Format article data into APA style reference\"\"\"\n",
        "    try:\n",
        "        # Get authors\n",
        "        if 'AuthorList' in article:\n",
        "            authors = article['AuthorList']\n",
        "            if len(authors) > 6:\n",
        "                author_text = f\"{authors[0]['LastName']}, {authors[0].get('ForeName', '')[0]}., et al.\"\n",
        "            else:\n",
        "                author_list = []\n",
        "                for author in authors:\n",
        "                    if 'ForeName' in author:\n",
        "                        author_list.append(f\"{author['LastName']}, {author['ForeName'][0]}.\")\n",
        "                    else:\n",
        "                        author_list.append(f\"{author['LastName']}\")\n",
        "                author_text = \", \".join(author_list[:-1]) + \" & \" + author_list[-1] if len(author_list) > 1 else author_list[0]\n",
        "        else:\n",
        "            author_text = \"No author\"\n",
        "\n",
        "        # Get year\n",
        "        pub_date = article['Journal']['JournalIssue']['PubDate']\n",
        "        year = pub_date.get('Year', 'n.d.')\n",
        "\n",
        "        # Get title\n",
        "        title = article.get('ArticleTitle', 'No title')\n",
        "        \n",
        "        # Get journal info\n",
        "        journal = article['Journal']\n",
        "        journal_title = journal.get('Title', journal.get('ISOAbbreviation', 'No journal'))\n",
        "        \n",
        "        # Get volume, issue, pages\n",
        "        volume = journal['JournalIssue'].get('Volume', '')\n",
        "        issue = journal['JournalIssue'].get('Issue', '')\n",
        "        pagination = article.get('Pagination', {}).get('MedlinePgn', '')\n",
        "\n",
        "        # Format the reference\n",
        "        reference = f\"{author_text} ({year}). {title}. {journal_title}\"\n",
        "        if volume:\n",
        "            reference += f\", {volume}\"\n",
        "        if issue:\n",
        "            reference += f\"({issue})\"\n",
        "        if pagination:\n",
        "            reference += f\", {pagination}\"\n",
        "        reference += \".\"\n",
        "\n",
        "        return reference\n",
        "    except Exception as e:\n",
        "        return f\"Error formatting reference: {str(e)}\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 4. Query DB: Searching Corrosion Genes\n",
        "This function search on PubMed database the bacteria in the list for different criteria related to corrosion, in order to found which of the bacteria has been previouly identified as causing damage by corrosion. The funciton search various terms used in corrosion and metabolic pathways, then the literature_analysis is done."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "def search_corrosion_genes(bacteria_name, base_dir, Literatur_dir, gid_dict):\n",
        "    \"\"\"\n",
        "    Search for specific corrosion-related genes and pathways for a given bacteria\n",
        "    \n",
        "    Parameters:\n",
        "    bacteria_name: str - name of the bacteria to search\n",
        "    base_dir: Path - base directory for saving results\n",
        "    Literatur_dir: Path - directory for literature results\n",
        "    gid_dict: dict - mapping of bacteria names to their GIDs\n",
        "    \"\"\"\n",
        "    # Get GID for this bacteria\n",
        "    bacteria_gid = gid_dict.get(bacteria_name, f\"NEW_{bacteria_name}\")  # Use NEW_ prefix for new bacteria\n",
        "    \n",
        "    # Defining the results file within base_dir\n",
        "    results_file = base_dir / \"bacteria_corrosion_summary.xlsx\"\n",
        "\n",
        "    # Add timing for individual bacteria\n",
        "    bacteria_start_time = time.time()\n",
        "    print(f\"Starting search for {bacteria_name} at: {datetime.now().strftime('%H:%M:%S')}\")\n",
        "    \n",
        "    results = {\n",
        "        'bacteria': bacteria_name,\n",
        "        'sulfate_reduction': False,\n",
        "        'metal_reduction': False,\n",
        "        'corrosion_associated': False,\n",
        "        'cytochrome_c3': False,\n",
        "        'acid_production': False,\n",
        "        'biofilm_formation': False,\n",
        "        'h2s_production': False,\n",
        "        'literature_count': 0,\n",
        "        'evidence': [],\n",
        "        'processing_time': 0\n",
        "    }\n",
        "    \n",
        "    # Creating a structured record for each bacteria\n",
        "    bacteria_record = {\n",
        "        'Name': bacteria_name,\n",
        "        'Metabolism': [],\n",
        "        'Terms': [],\n",
        "        'Hits': 0,\n",
        "        'Last_Reference': '',\n",
        "        'Abstract': ''\n",
        "    }\n",
        "    \n",
        "    try:\n",
        "        # 1. Check KEGG for pathways and genes\n",
        "        base_url = \"http://rest.kegg.jp/\"\n",
        "        \n",
        "        # Look for pathway modules\n",
        "        pathway_response = requests.get(f\"{base_url}find/module/{bacteria_name}\")\n",
        "        pathway_text = pathway_response.text.lower()\n",
        "        \n",
        "        # Define search terms\n",
        "        sulfate_terms = [\n",
        "        'sulfate', 'sulphate', \n",
        "        'dsrab', 'dsra', 'dsrb',  # Breaking down dsrAB into individual components\n",
        "        'aprab', 'apra', 'aprb',  # Breaking down aprAB into individual components\n",
        "        'sulfite', 'sulphite',\n",
        "        'sat',  # Sulfate adenylyltransferase\n",
        "        'sox',  # Sulfur oxidation\n",
        "        'sir',  # Sulfite reductase\n",
        "        'aps'   # Adenosine phosphosulfate\n",
        "        ]           \n",
        "               \n",
        "        metal_terms = [\n",
        "                    'metal', 'iron', 'fe(iii)', 'metal deterioration', 'MIC',\n",
        "                    'cytochrome', 'corrosion', 'biocorrosion',\n",
        "                    'methane corrosion', 'methanogenesis corrosion',\n",
        "                    'bacteria corrosion', 'anaerobic corrosion',\n",
        "                    'biofilm corrosion', 'manganese corrosion',\n",
        "                    'denitrification corrosion',\n",
        "                    'mtr',  # Metal reduction\n",
        "                    'omc',  # Outer membrane cytochromes\n",
        "                    'pil',  # Pili genes involved in metal reduction\n",
        "                    'cymA',  # Cytoplasmic membrane protein\n",
        "                    'hydA',  # Hydrogenase\n",
        "                    'feo',  # Ferrous iron transport\n",
        "                    'nrf',   # Nitrite reduction\n",
        "                    'organic acid AND corrosion',\n",
        "                    'acid metabolite AND metal deterioration',\n",
        "                    'fermentation AND corrosion',\n",
        "                    'biofilm AND (corrosion OR MIC)',\n",
        "                    'hydrogen sulfide AND corrosion',\n",
        "                    'thiosulfate AND corrosion'\n",
        "                ]\n",
        "\n",
        "        # Check pathway text\n",
        "        if any(term in pathway_text for term in sulfate_terms):\n",
        "            results['sulfate_reduction'] = True\n",
        "            results['evidence'].append(f\"Found sulfate pathway: {[term for term in sulfate_terms if term in pathway_text]}\")\n",
        "        \n",
        "        if any(term in pathway_text for term in metal_terms):\n",
        "            results['metal_reduction'] = True\n",
        "            results['evidence'].append(f\"Found metal pathway: {[term for term in metal_terms if term in pathway_text]}\")\n",
        "        \n",
        "        # Look for genes\n",
        "        genes_response = requests.get(f\"{base_url}find/genes/{bacteria_name}\")\n",
        "        genes_text = genes_response.text.lower()\n",
        "        \n",
        "        if \"cytochrome c3\" in genes_text:\n",
        "            results['cytochrome_c3'] = True\n",
        "            results['evidence'].append(\"Found cytochrome c3 gene\")\n",
        "        \n",
        "        if any(gene in genes_text for gene in ['dsr', 'apr', 'sat']):\n",
        "            results['sulfate_reduction'] = True\n",
        "            results['evidence'].append(f\"Found sulfate genes: {[gene for gene in ['dsr', 'apr', 'sat'] if gene in genes_text]}\")\n",
        "            \n",
        "    except Exception as e:\n",
        "        print(f\"KEGG API error for {bacteria_name}: {str(e)}\")\n",
        "    \n",
        "    # 2. Check literature\n",
        "    try:\n",
        "        Entrez.email = \"beatrizamandawatts@gmail.com\"\n",
        "        papers_details = []\n",
        "        \n",
        "        search_terms = [\n",
        "            f\"{bacteria_name}[Organism] AND (sulfate reduction OR dsrAB OR aprAB)\",\n",
        "            f\"{bacteria_name}[Organism] AND (metal reduction OR iron reduction)\",\n",
        "            f\"{bacteria_name}[Organism] AND cytochrome c3\",\n",
        "            f\"{bacteria_name}[Organism] AND corrosion\",\n",
        "            f\"{bacteria_name}[Organism] AND biocorrosion\",\n",
        "            f\"{bacteria_name}[Organism] AND (MIC OR 'microbiologically influenced corrosion')\",\n",
        "            f\"{bacteria_name}[Organism] AND 'material deterioration'\",\n",
        "            f\"{bacteria_name}[Organism] AND ('metal deterioration' OR 'metallic corrosion')\",\n",
        "            f\"{bacteria_name}[Organism] AND (acid production) AND (corrosion OR 'metal deterioration' OR MIC)\",\n",
        "            f\"{bacteria_name}[Organism] AND biofilm AND (corrosion OR MIC)\",\n",
        "            f\"{bacteria_name}[Organism] AND (hydrogen sulfide OR H2S) AND (corrosion OR 'metal deterioration')\"\n",
        "        ]\n",
        "        \n",
        "        for term in search_terms:\n",
        "            handle = Entrez.esearch(db=\"pubmed\", term=term)\n",
        "            record = Entrez.read(handle)\n",
        "            count = int(record[\"Count\"])\n",
        "            results['literature_count'] += count\n",
        "            \n",
        "            if count > 0:\n",
        "                results['evidence'].append(f\"Found {count} papers for: {term}\")\n",
        "                paper_ids = record[\"IdList\"]\n",
        "                \n",
        "                try:\n",
        "                    papers_handle = Entrez.efetch(db=\"pubmed\", id=paper_ids, rettype=\"medline\", retmode=\"xml\")\n",
        "                    papers = Entrez.read(papers_handle)\n",
        "                    \n",
        "                    # Update metabolism flags\n",
        "                    if \"sulfate\" in term.lower():\n",
        "                        results['sulfate_reduction'] = True\n",
        "                        if 'Sulfate Reduction' not in bacteria_record['Metabolism']:\n",
        "                            bacteria_record['Metabolism'].append('Sulfate Reduction')\n",
        "                    \n",
        "                    if \"metal\" in term.lower():\n",
        "                        results['metal_reduction'] = True\n",
        "                        if 'Metal Reduction' not in bacteria_record['Metabolism']:\n",
        "                            bacteria_record['Metabolism'].append('Metal Reduction')\n",
        "                    \n",
        "                    if \"cytochrome\" in term.lower():\n",
        "                        results['cytochrome_c3'] = True\n",
        "                        if 'Cytochrome c3' not in bacteria_record['Metabolism']:\n",
        "                            bacteria_record['Metabolism'].append('Cytochrome c3')\n",
        "                    \n",
        "                    bacteria_record['Hits'] += count\n",
        "                    bacteria_record['Terms'].append(f\"{term}: {count} hits\")\n",
        "                    \n",
        "                    # Process paper details\n",
        "                    if papers.get('PubmedArticle'):\n",
        "                        latest_paper = papers['PubmedArticle'][0]\n",
        "                        article = latest_paper['MedlineCitation']['Article']\n",
        "\n",
        "                        # Format reference in APA style\n",
        "                        bacteria_record['Last_Reference'] = format_apa_reference(article)\n",
        "                        \n",
        "                        # Get full abstract\n",
        "                        if 'Abstract' in article:\n",
        "                            abstract_text = article['Abstract']['AbstractText'][0]\n",
        "                            bacteria_record['Abstract'] = abstract_text  # Store full abstract\n",
        "\n",
        "                    time.sleep(1)  # Being nice to the APIs\n",
        "                    \n",
        "                except Exception as e:\n",
        "                    print(f\"Error processing PubMed data for {bacteria_name}: {e}\")       \n",
        "        # Save to Excel\n",
        "        try:\n",
        "            if results_file.exists():\n",
        "                df = pd.read_excel(results_file, index_col= 0)\n",
        "            else:\n",
        "                df = pd.DataFrame(columns=['Name', 'Metabolism', 'Terms', 'Hits', 'Last_Reference', 'Abstract'],\n",
        "                                                      index =pd.Index([], name ='GID'))\n",
        "            \n",
        "            # Convert lists to strings and ensure all fields exist\n",
        "            new_row = pd.DataFrame({\n",
        "                'Name': [bacteria_name],\n",
        "                'Metabolism': ['; '.join(bacteria_record['Metabolism']) if bacteria_record['Metabolism'] else ''],\n",
        "                'Terms': ['; '.join(bacteria_record['Terms']) if bacteria_record['Terms'] else ''],\n",
        "                'Hits': [bacteria_record['Hits']],\n",
        "                'Last_Reference': [bacteria_record.get('Last_Reference', '')],\n",
        "                'Abstract': [bacteria_record.get('Abstract', '')]\n",
        "            }, index=[bacteria_gid])\n",
        "            # Update or append\n",
        "            if bacteria_name in df['Name'].values:\n",
        "                df.loc[df['Name'] == bacteria_name] = new_row.iloc[0]\n",
        "            else:\n",
        "                df = pd.concat([df, new_row])\n",
        "                \n",
        "            # Generate timestamp for sheet name\n",
        "            sheet_name = f\"Analysis_{datetime.now().strftime('%Y%m%d_%H%M')}\"\n",
        "\n",
        "            # Adding the reference from the first function and the Abstract\n",
        "            with pd.ExcelWriter(results_file, engine='openpyxl') as writer:\n",
        "                # Write the DataFrame\n",
        "                df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
        "\n",
        "                # Get the worksheet\n",
        "                worksheet = writer.sheets[sheet_name]\n",
        "                \n",
        "                # Format the Abstract column for wrapping\n",
        "                for idx, col in enumerate(df.columns):\n",
        "                    if col == 'Abstract':\n",
        "                        # Make column wider and enable text wrapping\n",
        "                        worksheet.column_dimensions[openpyxl.utils.get_column_letter(idx + 1)].width = 50\n",
        "                        for cell in worksheet[openpyxl.utils.get_column_letter(idx + 1)]:\n",
        "                            cell.alignment = openpyxl.styles.Alignment(wrap_text=True)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error saving to Excel for {bacteria_name}: {e}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error in literature processing for {bacteria_name}: {e}\")\n",
        "\n",
        "    finally:\n",
        "        results['processing_time'] = time.time() - bacteria_start_time\n",
        "        print(f\"Finished {bacteria_name} in {results['processing_time']:.2f} seconds\")\n",
        "\n",
        "        return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "no"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "def search_corrosion_genes(bacteria_name, base_dir, Literatur_dir, gid_dict):\n",
        "    \"\"\"\n",
        "    Search for specific corrosion-related genes and pathways for a given bacteria\n",
        "    \n",
        "    Parameters:\n",
        "    bacteria_name: str - name of the bacteria to search\n",
        "    base_dir: Path - base directory for saving results\n",
        "    Literatur_dir: Path - directory for literature results\n",
        "    gid_dict: dict - mapping of bacteria names to their GIDs\n",
        "    \"\"\"\n",
        "        # Get GID for this bacteria\n",
        "    bacteria_gid = gid_dict.get(bacteria_name, f\"NEW_{bacteria_name}\")  # Use NEW_ prefix for new bacteria\n",
        "    \n",
        "    # Defining the results file within base_dir\n",
        "    timestamp = datetime.now().strftime('%Y%m%d_%H%M')\n",
        "    results_file = base_dir / f\"bacteria_corrosion_summary_{timestamp}.xlsx\"\n",
        "\n",
        "    # Add timing for individual bacteria\n",
        "    bacteria_start_time = time.time()\n",
        "    print(f\"Starting search for {bacteria_name} at: {datetime.now().strftime('%H:%M:%S')}\")\n",
        "    \n",
        "    results = {\n",
        "        'bacteria': bacteria_name,\n",
        "        'sulfate_reduction': False,\n",
        "        'metal_reduction': False,\n",
        "        'corrosion_associated': False,\n",
        "        'cytochrome_c3': False,\n",
        "        'acid_production': False,\n",
        "        'biofilm_formation': False,\n",
        "        'h2s_production': False,\n",
        "        'literature_count': 0,\n",
        "        'evidence': [],\n",
        "        'processing_time': 0\n",
        "    }\n",
        "    \n",
        "    # Creating a structured record for each bacteria\n",
        "    bacteria_record = {\n",
        "        'Name': bacteria_name,\n",
        "        'Metabolism': [],\n",
        "        'Terms': [],\n",
        "        'Hits': 0,\n",
        "        'Last_Reference': '',\n",
        "        'Abstract': ''\n",
        "    }\n",
        "    \n",
        "    try:\n",
        "        # 1. Check KEGG for pathways and genes\n",
        "        base_url = \"http://rest.kegg.jp/\"\n",
        "        \n",
        "        # Look for pathway modules\n",
        "        pathway_response = requests.get(f\"{base_url}find/module/{bacteria_name}\")\n",
        "        pathway_text = pathway_response.text.lower()\n",
        "        \n",
        "        # Define search terms\n",
        "        sulfate_terms = [\n",
        "        'sulfate', 'sulphate', \n",
        "        'dsrab', 'dsra', 'dsrb',  # Breaking down dsrAB into individual components\n",
        "        'aprab', 'apra', 'aprb',  # Breaking down aprAB into individual components\n",
        "        'sulfite', 'sulphite',\n",
        "        'sat',  # Sulfate adenylyltransferase\n",
        "        'sox',  # Sulfur oxidation\n",
        "        'sir',  # Sulfite reductase\n",
        "        'aps'   # Adenosine phosphosulfate\n",
        "        ]           \n",
        "               \n",
        "        metal_terms = [\n",
        "                    'metal', 'iron', 'fe(iii)', 'metal deterioration', 'MIC',\n",
        "                    'cytochrome', 'corrosion', 'biocorrosion',\n",
        "                    'methane corrosion', 'methanogenesis corrosion',\n",
        "                    'bacteria corrosion', 'anaerobic corrosion',\n",
        "                    'biofilm corrosion', 'manganese corrosion',\n",
        "                    'denitrification corrosion',\n",
        "                    'mtr',  # Metal reduction\n",
        "                    'omc',  # Outer membrane cytochromes\n",
        "                    'pil',  # Pili genes involved in metal reduction\n",
        "                    'cymA',  # Cytoplasmic membrane protein\n",
        "                    'hydA',  # Hydrogenase\n",
        "                    'feo',  # Ferrous iron transport\n",
        "                    'nrf',   # Nitrite reduction\n",
        "                    'organic acid AND corrosion',\n",
        "                    'acid metabolite AND metal deterioration',\n",
        "                    'fermentation AND corrosion',\n",
        "                    'biofilm AND (corrosion OR MIC)',\n",
        "                    'hydrogen sulfide AND corrosion',\n",
        "                    'thiosulfate AND corrosion'\n",
        "                ]\n",
        "\n",
        "        # Check pathway text\n",
        "        if any(term in pathway_text for term in sulfate_terms):\n",
        "            results['sulfate_reduction'] = True\n",
        "            results['evidence'].append(f\"Found sulfate pathway: {[term for term in sulfate_terms if term in pathway_text]}\")\n",
        "        \n",
        "        if any(term in pathway_text for term in metal_terms):\n",
        "            results['metal_reduction'] = True\n",
        "            results['evidence'].append(f\"Found metal pathway: {[term for term in metal_terms if term in pathway_text]}\")\n",
        "        \n",
        "        # Look for genes\n",
        "        genes_response = requests.get(f\"{base_url}find/genes/{bacteria_name}\")\n",
        "        genes_text = genes_response.text.lower()\n",
        "        \n",
        "        if \"cytochrome c3\" in genes_text:\n",
        "            results['cytochrome_c3'] = True\n",
        "            results['evidence'].append(\"Found cytochrome c3 gene\")\n",
        "        \n",
        "        if any(gene in genes_text for gene in ['dsr', 'apr', 'sat']):\n",
        "            results['sulfate_reduction'] = True\n",
        "            results['evidence'].append(f\"Found sulfate genes: {[gene for gene in ['dsr', 'apr', 'sat'] if gene in genes_text]}\")\n",
        "            \n",
        "    except Exception as e:\n",
        "        print(f\"KEGG API error for {bacteria_name}: {str(e)}\")\n",
        "    \n",
        "    # 2. Check literature\n",
        "    try:\n",
        "        Entrez.email = \"beatrizamandawatts@gmail.com\"\n",
        "        papers_details = []\n",
        "        \n",
        "        search_terms = [\n",
        "            f\"{bacteria_name}[Organism] AND (sulfate reduction OR dsrAB OR aprAB)\",\n",
        "            f\"{bacteria_name}[Organism] AND (metal reduction OR iron reduction)\",\n",
        "            f\"{bacteria_name}[Organism] AND cytochrome c3\",\n",
        "            f\"{bacteria_name}[Organism] AND corrosion\",\n",
        "            f\"{bacteria_name}[Organism] AND biocorrosion\",\n",
        "            f\"{bacteria_name}[Organism] AND (MIC OR 'microbiologically influenced corrosion')\",\n",
        "            f\"{bacteria_name}[Organism] AND 'material deterioration'\",\n",
        "            f\"{bacteria_name}[Organism] AND ('metal deterioration' OR 'metallic corrosion')\",\n",
        "            f\"{bacteria_name}[Organism] AND (acid production) AND (corrosion OR 'metal deterioration' OR MIC)\",\n",
        "            f\"{bacteria_name}[Organism] AND biofilm AND (corrosion OR MIC)\",\n",
        "            f\"{bacteria_name}[Organism] AND (hydrogen sulfide OR H2S) AND (corrosion OR 'metal deterioration')\"\n",
        "        ]\n",
        "        \n",
        "        for term in search_terms:\n",
        "            handle = Entrez.esearch(db=\"pubmed\", term=term)\n",
        "            record = Entrez.read(handle)\n",
        "            count = int(record[\"Count\"])\n",
        "            results['literature_count'] += count\n",
        "            \n",
        "            if count > 0:\n",
        "                results['evidence'].append(f\"Found {count} papers for: {term}\")\n",
        "                paper_ids = record[\"IdList\"]\n",
        "                \n",
        "                try:\n",
        "                    papers_handle = Entrez.efetch(db=\"pubmed\", id=paper_ids, rettype=\"medline\", retmode=\"xml\")\n",
        "                    papers = Entrez.read(papers_handle)\n",
        "                    \n",
        "                    # Update metabolism flags\n",
        "                    if \"sulfate\" in term.lower():\n",
        "                        results['sulfate_reduction'] = True\n",
        "                        if 'Sulfate Reduction' not in bacteria_record['Metabolism']:\n",
        "                            bacteria_record['Metabolism'].append('Sulfate Reduction')\n",
        "                    \n",
        "                    if \"metal\" in term.lower():\n",
        "                        results['metal_reduction'] = True\n",
        "                        if 'Metal Reduction' not in bacteria_record['Metabolism']:\n",
        "                            bacteria_record['Metabolism'].append('Metal Reduction')\n",
        "                    \n",
        "                    if \"cytochrome\" in term.lower():\n",
        "                        results['cytochrome_c3'] = True\n",
        "                        if 'Cytochrome c3' not in bacteria_record['Metabolism']:\n",
        "                            bacteria_record['Metabolism'].append('Cytochrome c3')\n",
        "                    \n",
        "                    bacteria_record['Hits'] += count\n",
        "                    bacteria_record['Terms'].append(f\"{term}: {count} hits\")\n",
        "                    \n",
        "                    # Process paper details\n",
        "                    if papers.get('PubmedArticle'):\n",
        "                        latest_paper = papers['PubmedArticle'][0]\n",
        "                        article = latest_paper['MedlineCitation']['Article']\n",
        "\n",
        "                        # Format reference in APA style\n",
        "                        bacteria_record['Last_Reference'] = format_apa_reference(article)\n",
        "                        \n",
        "                        # Get full abstract\n",
        "                        if 'Abstract' in article:\n",
        "                            abstract_text = article['Abstract']['AbstractText'][0]\n",
        "                            bacteria_record['Abstract'] = abstract_text  # Store full abstract\n",
        "\n",
        "                    time.sleep(1)  # Being nice to the APIs\n",
        "                    \n",
        "                except Exception as e:\n",
        "                    print(f\"Error processing PubMed data for {bacteria_name}: {e}\")       \n",
        "        # Save to Excel\n",
        "        try:\n",
        "            if results_file.exists():\n",
        "                df = pd.read_excel(results_file, index_col= 0)\n",
        "            else:\n",
        "                df = pd.DataFrame(columns=['Name', 'Metabolism', 'Terms', 'Hits', 'Last_Reference', 'Abstract'],\n",
        "                                                      index =pd.Index([], name ='GID'))\n",
        "            \n",
        "            # Convert lists to strings and ensure all fields exist\n",
        "            new_row = pd.DataFrame({\n",
        "                'Name': [bacteria_name],\n",
        "                'Metabolism': ['; '.join(bacteria_record['Metabolism']) if bacteria_record['Metabolism'] else ''],\n",
        "                'Terms': ['; '.join(bacteria_record['Terms']) if bacteria_record['Terms'] else ''],\n",
        "                'Hits': [bacteria_record['Hits']],\n",
        "                'Last_Reference': [bacteria_record.get('Last_Reference', '')],\n",
        "                'Abstract': [bacteria_record.get('Abstract', '')]\n",
        "            }, index=[bacteria_gid])\n",
        "            # Update or append\n",
        "            if bacteria_name in df['Name'].values:\n",
        "                df.loc[df['Name'] == bacteria_name] = new_row.iloc[0]\n",
        "            else:\n",
        "                df = pd.concat([df, new_row])\n",
        "                \n",
        "            # Generate timestamp for sheet name\n",
        "            sheet_name = f\"Analysis_{datetime.now().strftime('%Y%m%d_%H%M')}\"\n",
        "\n",
        "            # Adding the reference from the first function and the Abstract\n",
        "            with pd.ExcelWriter(str(results_file), engine='openpyxl', mode='w') as writer:\n",
        "                # Write the DataFrame to the main analysis sheet\n",
        "                df.to_excel(writer, sheet_name=sheet_name, index= True)\n",
        "    \n",
        "                # Get the worksheet for formatting\n",
        "                worksheet = writer.sheets[sheet_name]\n",
        "                \n",
        "                # Format the Abstract column for wrapping\n",
        "                for idx, col in enumerate(df.columns):\n",
        "                    if col == 'Abstract':\n",
        "                        # Make column wider and enable text wrapping\n",
        "                        worksheet.column_dimensions[openpyxl.utils.get_column_letter(idx +2)].width = 50\n",
        "                        for cell in worksheet[openpyxl.utils.get_column_letter(idx + 2)]:\n",
        "                            cell.alignment = openpyxl.styles.Alignment(wrap_text=True)\n",
        "                # References sheet\n",
        "                if 'Last_Reference' in df.columns:\n",
        "                    references_df = df[['Name', 'Last_Reference']].copy()\n",
        "                    references_df.to_excel(writer, sheet_name='References', index=True)\n",
        "                \n",
        "                # Abstracts sheet\n",
        "                if 'Abstract' in df.columns:\n",
        "                    abstracts_df = df[['Name', 'Abstract']].copy()\n",
        "                    abstracts_df.to_excel(writer, sheet_name='Abstracts', index=True)\n",
        "\n",
        "                    # Format after writing all sheets\n",
        "                    for sheet in writer.sheets.values():\n",
        "                        # Format the Abstract column if it exists in this sheet\n",
        "                        for idx, col in enumerate(sheet.iter_cols(1, sheet.max_column)):\n",
        "                            header = col[0].value\n",
        "                            if header == 'Abstract':\n",
        "                                sheet.column_dimensions[openpyxl.utils.get_column_letter(idx + 1)].width = 50\n",
        "                                for cell in col[1:]:  # Skip header\n",
        "                                    cell.alignment = openpyxl.styles.Alignment(wrap_text=True)\n",
        "                                    writer.close() \n",
        "        except Exception as e:\n",
        "            print(f\"Error saving to Excel for {bacteria_name}: {e}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error in literature processing for {bacteria_name}: {e}\")\n",
        "\n",
        "    finally:\n",
        "        results['processing_time'] = time.time() - bacteria_start_time\n",
        "        print(f\"Finished {bacteria_name} in {results['processing_time']:.2f} seconds\")\n",
        "\n",
        "        return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing bacteria: Anaerococcus\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "name 'result' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessing bacteria: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAnaerococcus\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mResults: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mresult\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# Your results dictionary\u001b[39;00m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'result' is not defined"
          ]
        }
      ],
      "source": [
        "print(f\"Processing bacteria: {'Anaerococcus'}\")\n",
        "print(f\"Results: {result}\")  # Your results dictionary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting search for Anaerococcus at: 12:58:06\n",
            "Error saving to Excel for Anaerococcus: [Errno 2] No such file or directory: '/home/beatriz/MIC/2_Micro/data_MIC/bacteria_corrosion_summary.xlsx'\n",
            "Finished Anaerococcus in 19.08 seconds\n",
            "\n",
            "Results for Anaerococcus:\n",
            "Sulfate reduction: False\n",
            "Metal reduction: False\n",
            "Cytochrome c3: False\n",
            "Literature count: 7\n",
            "Evidence: \n",
            "- Found 7 papers for: Anaerococcus[Organism] AND (MIC OR 'microbiologically influenced corrosion')\n",
            "Starting search for Aquamicrobium at: 12:58:25\n",
            "Error saving to Excel for Aquamicrobium: [Errno 2] No such file or directory: '/home/beatriz/MIC/2_Micro/data_MIC/bacteria_corrosion_summary.xlsx'\n",
            "Finished Aquamicrobium in 16.90 seconds\n",
            "\n",
            "Results for Aquamicrobium:\n",
            "Sulfate reduction: True\n",
            "Metal reduction: False\n",
            "Cytochrome c3: False\n",
            "Literature count: 1\n",
            "Evidence: \n",
            "- Found 1 papers for: Aquamicrobium[Organism] AND (sulfate reduction OR dsrAB OR aprAB)\n",
            "Starting search for Azospira at: 12:58:42\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[18], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# For your selected bacteria\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m bacteria \u001b[38;5;129;01min\u001b[39;00m selected_list:\n\u001b[0;32m----> 3\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43msearch_corrosion_genes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbacteria\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbase_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mLiteratur_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mselected_GID\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mResults for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbacteria\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSulfate reduction: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msulfate_reduction\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
            "Cell \u001b[0;32mIn[17], line 97\u001b[0m, in \u001b[0;36msearch_corrosion_genes\u001b[0;34m(bacteria_name, base_dir, Literatur_dir, gid_dict)\u001b[0m\n\u001b[1;32m     94\u001b[0m     results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mevidence\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound metal pathway: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m[term\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mterm\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39mmetal_terms\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mif\u001b[39;00m\u001b[38;5;250m \u001b[39mterm\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39mpathway_text]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     96\u001b[0m \u001b[38;5;66;03m# Look for genes\u001b[39;00m\n\u001b[0;32m---> 97\u001b[0m genes_response \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mbase_url\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43mfind/genes/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mbacteria_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     98\u001b[0m genes_text \u001b[38;5;241m=\u001b[39m genes_response\u001b[38;5;241m.\u001b[39mtext\u001b[38;5;241m.\u001b[39mlower()\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcytochrome c3\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m genes_text:\n",
            "File \u001b[0;32m~/MIC/2_Micro/.venv/lib/python3.10/site-packages/requests/api.py:73\u001b[0m, in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(url, params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     63\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \n\u001b[1;32m     65\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mget\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/MIC/2_Micro/.venv/lib/python3.10/site-packages/requests/api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/MIC/2_Micro/.venv/lib/python3.10/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    587\u001b[0m }\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
            "File \u001b[0;32m~/MIC/2_Micro/.venv/lib/python3.10/site-packages/requests/sessions.py:724\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    721\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m allow_redirects:\n\u001b[1;32m    722\u001b[0m     \u001b[38;5;66;03m# Redirect resolving generator.\u001b[39;00m\n\u001b[1;32m    723\u001b[0m     gen \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresolve_redirects(r, request, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 724\u001b[0m     history \u001b[38;5;241m=\u001b[39m [resp \u001b[38;5;28;01mfor\u001b[39;00m resp \u001b[38;5;129;01min\u001b[39;00m gen]\n\u001b[1;32m    725\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    726\u001b[0m     history \u001b[38;5;241m=\u001b[39m []\n",
            "File \u001b[0;32m~/MIC/2_Micro/.venv/lib/python3.10/site-packages/requests/sessions.py:724\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    721\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m allow_redirects:\n\u001b[1;32m    722\u001b[0m     \u001b[38;5;66;03m# Redirect resolving generator.\u001b[39;00m\n\u001b[1;32m    723\u001b[0m     gen \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresolve_redirects(r, request, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 724\u001b[0m     history \u001b[38;5;241m=\u001b[39m [resp \u001b[38;5;28;01mfor\u001b[39;00m resp \u001b[38;5;129;01min\u001b[39;00m gen]\n\u001b[1;32m    725\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    726\u001b[0m     history \u001b[38;5;241m=\u001b[39m []\n",
            "File \u001b[0;32m~/MIC/2_Micro/.venv/lib/python3.10/site-packages/requests/sessions.py:265\u001b[0m, in \u001b[0;36mSessionRedirectMixin.resolve_redirects\u001b[0;34m(self, resp, req, stream, timeout, verify, cert, proxies, yield_requests, **adapter_kwargs)\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m req\n\u001b[1;32m    264\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 265\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    266\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    267\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverify\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverify\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcert\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43madapter_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    276\u001b[0m     extract_cookies_to_jar(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcookies, prepared_request, resp\u001b[38;5;241m.\u001b[39mraw)\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;66;03m# extract redirect url, if any, for the next loop\u001b[39;00m\n",
            "File \u001b[0;32m~/MIC/2_Micro/.venv/lib/python3.10/site-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
            "File \u001b[0;32m~/MIC/2_Micro/.venv/lib/python3.10/site-packages/requests/adapters.py:667\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    664\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m TimeoutSauce(connect\u001b[38;5;241m=\u001b[39mtimeout, read\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    666\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 667\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    668\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    669\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    670\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    677\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    678\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    681\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    682\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request\u001b[38;5;241m=\u001b[39mrequest)\n",
            "File \u001b[0;32m~/MIC/2_Micro/.venv/lib/python3.10/site-packages/urllib3/connectionpool.py:789\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    786\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    788\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[0;32m--> 789\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    790\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    791\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    800\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    801\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    802\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    804\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[1;32m    805\u001b[0m clean_exit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
            "File \u001b[0;32m~/MIC/2_Micro/.venv/lib/python3.10/site-packages/urllib3/connectionpool.py:536\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    534\u001b[0m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[1;32m    535\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 536\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    538\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mread_timeout)\n",
            "File \u001b[0;32m~/MIC/2_Micro/.venv/lib/python3.10/site-packages/urllib3/connection.py:507\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    504\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mresponse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HTTPResponse\n\u001b[1;32m    506\u001b[0m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[0;32m--> 507\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    509\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    510\u001b[0m     assert_header_parsing(httplib_response\u001b[38;5;241m.\u001b[39mmsg)\n",
            "File \u001b[0;32m/usr/lib/python3.10/http/client.py:1375\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1373\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1374\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1375\u001b[0m         \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1376\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[1;32m   1377\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
            "File \u001b[0;32m/usr/lib/python3.10/http/client.py:318\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 318\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
            "File \u001b[0;32m/usr/lib/python3.10/http/client.py:279\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 279\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    280\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[1;32m    281\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[0;32m/usr/lib/python3.10/socket.py:705\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 705\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    707\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
            "File \u001b[0;32m/usr/lib/python3.10/ssl.py:1303\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1299\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1300\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1301\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1302\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1303\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1304\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1305\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
            "File \u001b[0;32m/usr/lib/python3.10/ssl.py:1159\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1157\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1158\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1159\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1160\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1161\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# For your selected bacteria\n",
        "for bacteria in selected_list:\n",
        "    result = search_corrosion_genes(bacteria, base_dir, Literatur_dir, selected_GID)\n",
        "    print(f\"\\nResults for {bacteria}:\")\n",
        "    print(f\"Sulfate reduction: {result['sulfate_reduction']}\")\n",
        "    print(f\"Metal reduction: {result['metal_reduction']}\")\n",
        "    print(f\"Cytochrome c3: {result['cytochrome_c3']}\")\n",
        "    print(f\"Literature count: {result['literature_count']}\")\n",
        "    print(\"Evidence:\", \"\\n- \".join([''] + result['evidence']))\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'results_file' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSaving file to: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mresults_file\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataFrame head:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mdf\u001b[38;5;241m.\u001b[39mhead()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'results_file' is not defined"
          ]
        }
      ],
      "source": [
        "print(f\"Saving file to: {results_file}\")\n",
        "print(f\"DataFrame head:\\n{df.head()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 6. Analysing the Search Results\n",
        "\n",
        "In summary the Bacteria found to be influencing the label corrosion, most of them have been already identified with corrosion on a way or another.The Results table give us a visual of the bacteria name, the mecanism for which is known to be influencing corrosion, the numbers of hits on the literature with such claims. The reference of the final article and the abstract corresponding could be found on the following sheets.The structure is like this: \n",
        "Main file: bacteria_corrosion_summary.xlsx with sheets:\n",
        "\n",
        "Sheet 1: Analysis results (metabolism, hits, etc.) --> from search_corrosion_genes function\n",
        "Sheet 2: References in APA format--> from format_apa_reference and search_corrosion_genes functions\n",
        "Sheet 3: Abstracts--> from format_apa_reference and search_corrosion_genes functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zj1WrS4F1vwY"
      },
      "source": [
        "Especialised db\n",
        "MicrobeDB\n",
        "GOLD (Genomes Online Database)\n",
        "PATRIC Bacterial Bioinformatics Resource\n",
        "\n",
        "QIIME2 (Microbiome analysis)\n",
        "MetaPhlAn (Metagenomic profiling)\n",
        "MG-RAST (Metagenome analysis)\n",
        "Prokka (Genome annotation)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JxskxZFX1vwZ"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vV_6x0vm1vwZ"
      },
      "source": [
        "# Biomarkers Refinement\n",
        "Prioritize bacteria with known corrosion-related activities\n",
        "Consider biofilm formation capabilities\n",
        "Look for known metal-oxidizing/reducing bacteria\n",
        "Factor in pH tolerance and oxygen requirements\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D62G-wXz1vwZ"
      },
      "source": [
        "functional annotation analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "arbbwDgh1vwZ"
      },
      "source": [
        "3. Metabolic Pathway Analysis and mapping-\n",
        "PICRUSt2 - Can predict metabolic functions from 16S data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "wvT2KVJK1vwZ"
      },
      "outputs": [
        {
          "ename": "SyntaxError",
          "evalue": "invalid syntax (1207116454.py, line 2)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;36m  Cell \u001b[0;32mIn[13], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    conda create -n picrust2 -c bioconda -c conda-forge picrust2\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ],
      "source": [
        "bashCopy# Install PICRUSt2 (if not already installed)\n",
        "conda create -n picrust2 -c bioconda -c conda-forge picrust2\n",
        "\n",
        "# Activate the environment\n",
        "conda activate picrust2\n",
        "\n",
        "# Run full pipeline\n",
        "picrust2_pipeline.py -s your_sequences.fasta -i your_abundance.biom -o picrust2_output_folder\n",
        "\n",
        "# For more specific pathway analysis\n",
        "add_descriptions.py -i EC_metagenome_out/pred_metagenome_unstrat.tsv.gz -m EC \\\n",
        "                   -o EC_metagenome_out/pred_metagenome_unstrat_described.tsv.gz\n",
        "\n",
        "Requirements:\n",
        "\n",
        "\n",
        "Your sequences should be properly quality filtered\n",
        "Sequences should be aligned and trimmed to the same length\n",
        "ASVs/OTUs should be properly clustered\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iVbvuUla1vwZ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "crhvOZNC1vwZ"
      },
      "source": [
        "# Network analysis\n",
        "\n",
        "Ecological Networks:\n",
        "\n",
        "\n",
        "Bacteria that appear \"neutral\" alone might be critical support species\n",
        "They could be enabling or moderating the effects of the corrosion-significant species\n",
        "In microbial communities, some species act as \"keystone\" species not through abundance but through their metabolic interactions\n",
        "\n",
        "\n",
        "Stability Indicators:\n",
        "\n",
        "\n",
        "Species present across all conditions might be:\n",
        "\n",
        "Buffer species that maintain community stability\n",
        "Indicators of baseline environmental conditions\n",
        "Part of the core microbiome that enables other species to thrive\n",
        "\n",
        "Think of it like a metal alloy - some elements might not directly affect corrosion resistance, but their presence maintains the overall structure that makes the protective elements effective.\n",
        "However, if data size/processing is a significant concern, you could:\n",
        "\n",
        "Keep full bacterial data initially\n",
        "Run your analysis\n",
        "Check if removing the \"uniform\" species significantly changes your results\n",
        "Document which removals affect the model and which don't\n",
        "_________________________\n",
        "This is to understand genus interactions\n",
        "Group bacteria by their typical ecological roles (e.g., primary degraders, secondary degraders)\n",
        "Add known syntrophic relationships between genera\n",
        "Map carbon/nitrogen cycling capabilities\n",
        "Identify potential metabolic handoffs between community members\n",
        "__\n",
        "\n",
        "Map each genus to known electron acceptor preferences (Fe, Mn, S, etc.)\n",
        "Create functional groups based on these metabolic capabilities\n",
        "Compare distribution of these functional groups across your categories\n",
        "Look for enrichment patterns of specific metabolic types\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "82buZvfD1vwZ"
      },
      "source": [
        "# QIIME2 (Microbiome analysis)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kQ0cWVW61vwa"
      },
      "outputs": [],
      "source": [
        "# Import FASTA into QIIME 2\n",
        "qiime tools import \\\n",
        "  --input-path your_sequences.fasta \\\n",
        "  --output-path sequences.qza \\\n",
        "  --type 'FeatureData[Sequence]'\n",
        "\n",
        "# Run DADA2 or Deblur for ASV generation\n",
        "qiime dada2 denoise-single \\\n",
        "  --i-demultiplexed-seqs sequences.qza \\\n",
        "  --p-trim-left 0 \\\n",
        "  --p-trunc-len 250 \\\n",
        "  --o-representative-sequences rep-seqs.qza \\\n",
        "  --o-table table.qza\n",
        "\n",
        "# Export to BIOM format\n",
        "qiime tools export \\\n",
        "  --input-path table.qza \\\n",
        "  --output-path exported-table\n",
        "\n",
        "# Convert to TSV if needed\n",
        "biom convert \\\n",
        "  -i exported-table/feature-table.biom \\\n",
        "  -o feature-table.tsv \\\n",
        "  --to-tsv\n",
        "\n",
        "\n",
        "# Dereplicate sequences\n",
        "vsearch --derep_fulllength your_sequences.fasta \\\n",
        "        --output unique_sequences.fasta \\\n",
        "        --sizeout\n",
        "\n",
        "# Cluster at 97% similarity (for OTUs)\n",
        "vsearch --cluster_size unique_sequences.fasta \\\n",
        "        --id 0.97 \\\n",
        "        --centroids clustered_sequences.fasta\n",
        "\n",
        "# Create OTU table\n",
        "vsearch --usearch_global your_sequences.fasta \\\n",
        "        --db clustered_sequences.fasta \\\n",
        "        --id 0.97 \\\n",
        "        --otutabout otu_table.txt\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
